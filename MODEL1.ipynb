{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecfd6b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 85ms/step - accuracy: 0.6335 - loss: 2.2249 - val_accuracy: 0.7634 - val_loss: 2.0945\n",
      "Epoch 2/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.8237 - loss: 1.9326 - val_accuracy: 0.7922 - val_loss: 1.9987\n",
      "Epoch 3/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.9101 - loss: 1.7256 - val_accuracy: 0.7870 - val_loss: 1.9778\n",
      "Epoch 4/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9444 - loss: 1.5689 - val_accuracy: 0.7973 - val_loss: 1.9112\n",
      "Epoch 5/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9629 - loss: 1.4274 - val_accuracy: 0.7922 - val_loss: 1.8536\n",
      "Epoch 6/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9754 - loss: 1.3119 - val_accuracy: 0.7798 - val_loss: 1.8271\n",
      "Epoch 7/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9769 - loss: 1.2059 - val_accuracy: 0.7726 - val_loss: 1.9061\n",
      "Epoch 8/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9774 - loss: 1.1256 - val_accuracy: 0.7798 - val_loss: 1.7433\n",
      "Epoch 9/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9708 - loss: 1.0498 - val_accuracy: 0.7757 - val_loss: 1.7252\n",
      "Epoch 10/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9797 - loss: 0.9567 - val_accuracy: 0.7767 - val_loss: 1.6757\n",
      "Epoch 11/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9751 - loss: 0.9024 - val_accuracy: 0.7593 - val_loss: 1.7322\n",
      "Epoch 12/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9699 - loss: 0.8710 - val_accuracy: 0.7716 - val_loss: 1.6492\n",
      "Epoch 13/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9637 - loss: 0.8615 - val_accuracy: 0.7644 - val_loss: 1.6595\n",
      "Epoch 14/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9653 - loss: 0.8345 - val_accuracy: 0.7819 - val_loss: 1.6589\n",
      "Epoch 15/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9700 - loss: 0.7832 - val_accuracy: 0.7685 - val_loss: 1.5764\n",
      "Epoch 16/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9812 - loss: 0.7126 - val_accuracy: 0.7572 - val_loss: 1.5544\n",
      "Epoch 17/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9828 - loss: 0.6683 - val_accuracy: 0.7788 - val_loss: 1.5067\n",
      "Epoch 18/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9869 - loss: 0.6032 - val_accuracy: 0.7829 - val_loss: 1.4789\n",
      "Epoch 19/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9846 - loss: 0.5615 - val_accuracy: 0.7665 - val_loss: 1.4986\n",
      "Epoch 20/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9743 - loss: 0.5595 - val_accuracy: 0.7593 - val_loss: 1.5207\n",
      "Epoch 21/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9618 - loss: 0.5990 - val_accuracy: 0.7551 - val_loss: 1.6072\n",
      "Epoch 22/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.9575 - loss: 0.6300 - val_accuracy: 0.7613 - val_loss: 1.5187\n",
      "Epoch 23/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.9684 - loss: 0.5760 - val_accuracy: 0.7685 - val_loss: 1.4038\n",
      "Epoch 24/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9881 - loss: 0.5085 - val_accuracy: 0.7644 - val_loss: 1.3679\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "Final Training Accuracy: 0.9850823283195496\n",
      "Final Testing Accuracy: 0.7644032835960388\n",
      "\n",
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79       486\n",
      "           1       0.78      0.83      0.80       486\n",
      "\n",
      "    accuracy                           0.80       972\n",
      "   macro avg       0.80      0.80      0.80       972\n",
      "weighted avg       0.80      0.80      0.80       972\n",
      "\n",
      "Accuracy: 0.7973251028806584\n",
      "Precision: 0.7784200385356455\n",
      "Recall: 0.831275720164609\n",
      "F1-Score: 0.8039800995024876\n",
      "ROC AUC: 0.7973251028806585\n",
      "\n",
      "Confusion Matrix:\n",
      "[[371 115]\n",
      " [ 82 404]]\n",
      "False Positives: 115\n",
      "False Negatives: 82\n",
      "True Positives: 404\n",
      "True Negatives: 371\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"three_rows.csv\")\n",
    "\n",
    "# Extract target variable (Y)\n",
    "Y = df['label']\n",
    "\n",
    "# Identify categorical amino acid columns\n",
    "amino_acid_cols = [\"A1\", \"A2\", \"A3\"]\n",
    "\n",
    "# Apply One-Hot Encoding (OHE) for A1, A2, A3\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "encoded_amino_acids = encoder.fit_transform(df[amino_acid_cols])\n",
    "\n",
    "# Convert to DataFrame with proper column names\n",
    "encoded_cols = encoder.get_feature_names_out(amino_acid_cols)\n",
    "encoded_amino_acids_df = pd.DataFrame(encoded_amino_acids, columns=encoded_cols, index=df.index)\n",
    "\n",
    "# Drop original A1, A2, A3 columns from df\n",
    "df.drop(columns=amino_acid_cols, inplace=True)\n",
    "\n",
    "# Merge the encoded features back into the dataset\n",
    "df = pd.concat([df, encoded_amino_acids_df], axis=1)\n",
    "\n",
    "# Select all features starting from 'Feature_1_A1' onward\n",
    "feature_start_col = df.columns.get_loc(\"Feature_1_A1\")\n",
    "X_numerical_features = df.iloc[:, feature_start_col:].values\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_numerical_features_scaled = scaler.fit_transform(X_numerical_features)\n",
    "\n",
    "# Combine encoded categorical features with scaled numerical features\n",
    "X_independent = np.hstack((encoded_amino_acids, X_numerical_features_scaled))\n",
    "\n",
    "# Split dataset into training (80%) and testing (20%)\n",
    "X_train_final, X_test_final, Y_train_final, Y_test_final = train_test_split(\n",
    "    X_independent, Y, test_size=0.2, random_state=SEED, stratify=Y\n",
    ")\n",
    "\n",
    "# Define improved MLP model architecture\n",
    "mlp_model_final = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_final.shape[1],)),\n",
    "    \n",
    "    # Hidden layers with BatchNorm, reduced L2, and adjusted dropout\n",
    "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Dense(256, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Dense(128, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Dense(64, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "    layers.Dropout(0.1),\n",
    "    \n",
    "    # Output layer\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile model with custom learning rate\n",
    "mlp_model_final.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005), \n",
    "                        loss='binary_crossentropy', \n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "# Set up EarlyStopping callback with increased patience\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Train model with smaller batch size\n",
    "history_final = mlp_model_final.fit(\n",
    "    X_train_final, Y_train_final, epochs=400, batch_size=64,\n",
    "    validation_data=(X_test_final, Y_test_final), callbacks=[early_stopping], verbose=1\n",
    ")\n",
    "\n",
    "# Retrieve final training and testing accuracy\n",
    "final_train_accuracy = history_final.history['accuracy'][-1]  \n",
    "final_test_accuracy = history_final.history['val_accuracy'][-1]\n",
    "\n",
    "# Get predictions on test set\n",
    "Y_pred_final = mlp_model_final.predict(X_test_final)\n",
    "Y_pred_final = (Y_pred_final > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(Y_test_final, Y_pred_final)\n",
    "precision = precision_score(Y_test_final, Y_pred_final)\n",
    "recall = recall_score(Y_test_final, Y_pred_final)\n",
    "f1 = f1_score(Y_test_final, Y_pred_final)\n",
    "roc_auc = roc_auc_score(Y_test_final, Y_pred_final)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test_final, Y_pred_final)\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "# Print results\n",
    "print(f\"Final Training Accuracy: {final_train_accuracy}\")\n",
    "print(f\"Final Testing Accuracy: {final_test_accuracy}\")\n",
    "print(\"\\nFinal Classification Report:\")\n",
    "print(classification_report(Y_test_final, Y_pred_final))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"False Positives: {FP}\")\n",
    "print(f\"False Negatives: {FN}\")\n",
    "print(f\"True Positives: {TP}\")\n",
    "print(f\"True Negatives: {TN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc64a177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHFCAYAAAAe+pb9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACBMElEQVR4nO3dd1hT59sH8G9YYQkyFEEUJwW17m3dG4t11UXds2q1YGu1+nPUVlpHa90WFReOOrBqXWituyrugRvFhQMUFNk87x+8HIkEJJhwIPl+rotLz3NG7uQk5OaZCiGEABEREZEBMpI7ACIiIiK5MBEiIiIig8VEiIiIiAwWEyEiIiIyWEyEiIiIyGAxESIiIiKDxUSIiIiIDBYTISIiIjJYTISIiIjIYDER0iMrV66EQqGQfkxMTODs7IyePXvi5s2bcocHAChTpgz69+8vdxhZxMXF4eeff0aNGjVgbW0NKysrVK9eHTNmzEBcXJzc4eXajBkzsG3btizl//77LxQKBf799998jynDnTt3MGrUKLi7u8PCwgKWlpaoXLkyJk2ahIcPH0rHNWvWDFWqVJEtzg+xbt06zJ07V2fXz8vn5/jx45g6dSpevnyZZV+zZs3QrFkzrcSWoWXLlhg+fLi0nfHey/gxNjZGsWLF4O3tjdDQULXXEEJg3bp1aNGiBezs7KBUKlGuXDmMHDkS9+/fz/axd+zYAW9vbzg5OcHMzAz29vZo2bIlgoKCkJycDAB48eIFihYtqvZzkpPcvn+pEBKkNwIDAwUAERgYKE6cOCEOHjwofvzxR2FhYSGKFy8uoqOj5Q5RnD17Vty6dUvuMFRERkaKKlWqCAsLC/Hdd9+Jffv2iX379onx48cLCwsLUaVKFREZGSl3mLliZWUl+vXrl6U8JiZGnDhxQsTExOR/UEKIHTt2CCsrK+Hm5iZmzZol9u/fLw4cOCDmzp0rqlatKqpXry4d27RpU1G5cmVZ4vxQHTp0EG5ubjq7fl4+P7NmzRIARHh4eJZ9V65cEVeuXNFSdEJs27ZNKJVK8eDBA6ns4MGDAoCYMWOGOHHihDh8+LD4/fffhb29vbC0tBQ3btxQuUZqaqro0aOHACB69eoltm3bJg4ePCh+//134erqKooWLSqOHj2qck5aWpro37+/ACC8vLzE2rVrxaFDh8T27duFr6+vsLGxEXPnzpWOnzp1qqhQoYJITEzM1fPS5P1LhQ8TIT2SkQidPn1apXzatGkCgFixYoVMkckrJSVFJCQkZLu/TZs2wsTERBw5ciTLviNHjggTExPRtm1bXYao1vviVie7REhOd+7cEVZWVqJGjRri5cuXWfanpaWJLVu2SNv5kQilpaWJN2/eaP26ukqEPiTWnBIhbatbt67o2bOnSllGIrRp0yaV8lWrVgkAYvLkySrlM2bMEADEzz//nOX6kZGRws3NTTg5OYkXL15I5b/88osAIKZNm6Y2rsePH6t8viMjI4WJiYkICgp673PS9P37IZKSkkRycrJWrkW5x0RIj2SXCP39998CgPD391cpP336tPD29hZ2dnZCqVSK6tWri40bN2a57oMHD8SQIUOEq6urMDU1Fc7OzqJr164qtSQxMTFi7NixokyZMsLU1FS4uLiIMWPGiNevX6tcy83NTfqifvr0qTA1NRWTJk3K8phhYWECgPj999+lssePH4uhQ4eKkiVLClNTU1GmTBkxdepUlV8c4eHhAoD45ZdfxPTp00WZMmWEsbGx2L17t9rX7PTp0wKAGDZsWDavqhBDhw4VAERoaKhUBkCMHDlSLFmyRFSsWFGYmZkJT09PsX79+iznf2jc8fHxws/PT1SrVk3Y2NgIOzs7Ub9+fbFt2zaVxwGQ5adp06ZCiLdfRgcPHpSO79evn7CyshI3b94U7du3F1ZWVsLV1VX4+fllScDu378vunbtKqytrYWtra3o3bu3OHXqlFQDmZNRo0YJAOLEiRM5HpchIxE6deqU+OSTT4SFhYUoW7as8Pf3F6mpqdJxuX1dMl6bkSNHisWLFwsPDw9hamoqFi9eLIRIrx2oW7eusLOzE0WKFBE1atQQy5YtE2lpaVmuExQUJOrXry+srKyElZWVqFatmli2bJkUt7p7kCExMVFMnz5dfPTRR8LMzEw4OjqK/v37i6dPn6o8hpubm+jQoYPYsmWLqF69ulAqleK7776T9mVOdFNTU8X06dOFu7u7MDc3F7a2tuLjjz+Waj+mTJmiNqaM90HTpk2l90iGhIQEMW3aNOHh4SGUSqWwt7cXzZo1E8eOHcvxvp09e1YAEH///bdKeXaJ0JUrV7J89hITE4WdnZ3w9PRU+/oLIcS6desEADF79mwhRHryYG9vLzw8PLI9R5327duLxo0bv/c4Td+/796jDO++1hmvy+rVq4Wfn59wcXERCoVCnD9/XgCQ3leZ7dq1SwAQf/31l1R248YN0atXL1GsWDFhZmYmPDw8xIIFC3IVK6Uz0UFrGxUw4eHhAAB3d3ep7ODBg2jXrh3q1auHJUuWwNbWFhs2bECPHj3w5s0bqR/Cw4cPUadOHSQnJ+P7779H1apVERUVhb179+LFixdwcnLCmzdv0LRpUzx48EA65sqVK5g8eTIuXbqE/fv3Q6FQZImrWLFi+PTTT7Fq1SpMmzYNRkZvu6wFBgbCzMwMPj4+AIDIyEjUrVsXRkZGmDx5MsqXL48TJ07gxx9/xN27dxEYGKhy7Xnz5sHd3R2zZ8+GjY0NKlasqPa1CQkJAQB06tQp29evU6dO+OOPPxASEoJatWpJ5du3b8fBgwfxww8/wMrKCosWLUKvXr1gYmKCbt26aS3uxMREREdH45tvvkHJkiWRlJSE/fv3o0uXLggMDETfvn0BACdOnECLFi3QvHlz/O9//wMA2NjYZPu8ACA5ORkdO3bEoEGDMHbsWBw+fBjTp0+Hra0tJk+eDCC9/1Tz5s0RHR2NX375BRUqVMCePXvQo0ePHK+dYd++fXByckL9+vVzdXzG6+bj44OxY8diypQpCA4OxoQJE+Di4iI939y+Lhm2bduGI0eOYPLkyShRogSKFy8OALh79y6GDRuG0qVLAwD+++8/fPXVV3j48KH0GgDA5MmTMX36dHTp0gVjx46Fra0tLl++jHv37gEAFi1ahKFDh+L27dsIDg5Weey0tDR89tlnOHLkCMaNG4eGDRvi3r17mDJlCpo1a4bQ0FBYWFhIx589exZhYWGYNGkSypYtCysrK7Wv08yZMzF16lRMmjQJTZo0QXJyMq5duyb1Bxo8eDCio6Mxf/58bN26Fc7OzgCASpUqqb1eSkoK2rdvjyNHjuDrr79GixYtkJKSgv/++w8RERFo2LBhtvds586dMDY2RpMmTbI9JjN1v5fOnDmDFy9eYOjQoWp/ZwCAt7c3jIyMEBISgrFjxyI0NBTR0dEYMmRItueo06xZM0yYMAEvX75E0aJFsz0uL+9fTUyYMAENGjTAkiVLYGRkhFKlSqFGjRoIDAzEoEGDVI5duXIlihcvDi8vLwDA1atX0bBhQ5QuXRpz5sxBiRIlsHfvXowePRrPnz/HlClTdBKz3pE7EyPtyagR+u+//0RycrJ49eqV2LNnjyhRooRo0qSJSg2Eh4eHqFGjRpZq2E8//VQ4OztLf3kPHDhQmJqaiqtXr2b7uP7+/sLIyChLTdTmzZsFALFr1y6p7N2/lrZv3y4AiH379kllKSkpwsXFRXTt2lUqGzZsmLC2thb37t1TeYzZs2cLAFI/h4yalfLly4ukpKT3vWRi+PDhAoC4du1atsdk1E59+eWXUhkAYWFhoVIrlpKSIjw8PESFChV0GndKSopITk4WgwYNEjVq1FDZl13TWHY1QgDEn3/+qXKsl5eX+Oijj6TthQsXCgBZatWGDRuWqxohc3NzUb9+/RyPySyjZuXkyZMq5ZUqVcqxiTKn1wWAsLW1fW8/udTUVJGcnCx++OEH4eDgINUw3LlzRxgbGwsfH58cz8+uaWz9+vUCQJYmlIwayUWLFkllbm5uwtjYWFy/fj3Ldd79/Hz66afv7Z+SU9PYu7UUq1evFgBEQEBAjtdUp3379sLDwyNLecZ7b+PGjSI5OVm8efNGHDt2THz00UeiUqVKKk1cGzZsEADEkiVLcnwsJycn4enpqdE57woJCVH7vn6Xpu9fTWuEmjRpkuXYefPmCQAq74Ho6GihVCrF2LFjpbK2bdsKV1fXLH3/Ro0aJczNzQtEv9DCgKPG9FD9+vVhamqKIkWKoF27drCzs8Nff/0FE5P0CsBbt27h2rVrUm1LSkqK9OPl5YXHjx/j+vXrAIDdu3ejefPm8PT0zPbxdu7ciSpVqqB69eoq12rbtu17Ryq1b98eJUqUUKkZ2bt3Lx49eoSBAweqPEbz5s3h4uKi8hjt27cHABw6dEjluh07doSpqalmL1w2hBAAkOWvzZYtW8LJyUnaNjY2Ro8ePXDr1i08ePBAq3Fv2rQJjRo1grW1NUxMTGBqaorly5cjLCzsg56bQqGAt7e3SlnVqlWlWo6MGDPeS5n16tXrgx47JyVKlEDdunVzjAvQ7HXJGIH0rn/++QetWrWCra0tjI2NYWpqismTJyMqKgpPnz4FkF5zmJqaipEjR+bp+ezcuRNFixaFt7e3yvugevXqKFGiRJbPSNWqVVVqSrJTt25dXLhwASNGjMDevXsRGxubp/gy7N69G+bm5iqfvdx69OiRVMumTo8ePWBqagpLS0s0atQIsbGx+Pvvv3OsjcmOEEKj2h91MmKVe8RX165ds5T5+PhAqVRi5cqVUtn69euRmJiIAQMGAAASEhJw4MABdO7cGZaWlll+jyckJOC///7Lr6dRqDER0kOrV6/G6dOn8c8//2DYsGEICwtT+dJ68uQJAOCbb76Bqampys+IESMAAM+fPwcAPHv2DK6urjk+3pMnT3Dx4sUs1ypSpAiEENK11DExMUGfPn0QHBwsVeevXLkSzs7OaNu2rcpj7NixI8tjVK5cWSXeDBlNAO+T0RySUU2vzt27dwEApUqVUikvUaJElmMzyqKiorQW99atW9G9e3eULFkSa9euxYkTJ3D69GkMHDgQCQkJuXqe2bG0tIS5ublKmVKpVLluVFSUSsKXQV2ZOqVLl87x9VXHwcEhS5lSqUR8fLy0renrou61PXXqFNq0aQMACAgIwLFjx3D69GlMnDgRAKTHe/bsGQC897OQnSdPnuDly5cwMzPL8l6IjIzM8/t3woQJmD17Nv777z+0b98eDg4OaNmyZbbD0t/n2bNncHFxUWmmzq34+Pgs76XMfvnlF5w+fRqHDh3CxIkT8eTJE3Tq1AmJiYnSMbn5PMbFxeH58+fS5zE356iTEWvm95Q6eXn/akLdvba3t0fHjh2xevVqpKamAkj/vVi3bl3pd0dUVBRSUlIwf/78LO+pjKaznH730lvsI6SHPD09Ubt2bQBA8+bNkZqaimXLlmHz5s3o1q0bHB0dAaT/Eu3SpYvaa3z00UcA0vvxZNRuZMfR0REWFhZYsWJFtvtzMmDAAMyaNUvqo7R9+3Z8/fXXMDY2VrlG1apV8dNPP6m9houLi8p2bv9abN26Nb7//nts27YtS41Hhoz5Rlq3bq1SHhkZmeXYjLKML3JtxL127VqULVsWGzduVNmf+QtElxwcHHDq1Kks5eqevzpt27bF/Pnz8d9//2m1n4Wmr4u613bDhg0wNTXFzp07Vb7E351jplixYgCABw8eZEmIc8PR0REODg7Ys2eP2v1FihR5b6zqmJiYwM/PD35+fnj58iX279+P77//Hm3btsX9+/dhaWmpUZzFihXD0aNHkZaWpnEy5OjoiOjo6Gz3lytXTvq91KRJE1hYWGDSpEmYP38+vvnmGwBArVq1YGdnh+3bt8Pf31/t67B9+3akpaVJn8fatWvD3t4ef/31V7bnqJMR6/t+P2n6/jU3N1f7Hnz+/Lnax8ou3gEDBmDTpk0ICQlB6dKlcfr0aSxevFjab2dnB2NjY/Tp0yfbmsqyZcu+N14C+wjpk+xGjUVHR0sjMTL6/lSsWFF4eXm995oZfYRy6kPz448/CktLS3Hnzp33Xi+79vN69eqJunXrigULFqjtszN48GDh4uLy3jbvjL42s2bNem8sGTKGz787N4kQb4fPt2vXTqUcOfQRKl++vFbj7tKli0qfHSHSR6JZW1uLdz/C9vb2onv37lmukdOosXdljDTKkNFHKHNfLyFy30coN8OPt27dKm1nN3y+X79+Kv1vNHld8P+jxt7l5+cnrK2tVfplvXnzRpQuXVqlX014eLgwNjYWffr0yfG5dunSRRQvXjxL+dq1a6X+e++TMWosu33vmx5h7ty5Kv3PMvqbqOvnl10foeXLl783zncNHDhQ2NvbZynPbtRYUlKSqFChgnBwcBCxsbFSecbw+V9++SXLtZ48eSINn8/8Xnrf8PknT55k+XwHBQUJAOLChQs5Pi9N379t27YVlSpVUjnm+vXrwsTERG0foXdflwwpKSmiZMmSonv37uKbb74R5ubmWR6/VatWolq1armeD4nUYyKkR7JLhIQQYubMmQKAWLNmjRBCiH/++UcolUrRpk0bsW7dOnHo0CERHBwsZsyYIbp16yad9+DBA+Hs7CyKFy8u5s6dKw4cOCC2bNkihgwZIsLCwoQQQrx+/VrUqFFDuLq6ijlz5oiQkBCxd+9eERAQID7//HOVX/7Z/SJfunSpACBcXV1Fw4YNs+x/9OiRcHNzEx4eHmLRokXiwIED4u+//xYLFy4UHTp0EPfv3xdC5C0RyphQ0dLSUowfP16EhISIkJAQMWHCBGFpaal2QkUAolSpUqJSpUpi/fr1Yvv27aJdu3YCgNiwYYNW416xYoXUWfvAgQNi5cqVonz58qJixYpZvvCbNm0qihcvLrZv3y5Onz4tJZQfkgi9fv1aVKhQQdjb24tFixaJffv2CV9fX1GmTBkBQKxateq9r/GOHTuEpaWlKFOmjJg9e7Y4cOCAOHDggJg/f76oUaNGriZUfDcR0uR1yS4ROnDggAAgunXrJvbt2yfWr18vatWqJV0jcwfj//3vf9KxW7ZsEfv37xfz5s1TmQcn47VbtGiROHnypPRZTElJEe3btxf29vZi2rRpYvfu3WL//v1i5cqVol+/fipfpJokQp9++qkYP3682Lx5szh06JBYvXq1KFOmjHBzc5OSu4x7P2zYMHH8+HFx+vRpKfF4NxFKTk4WzZs3F6ampmLcuHFi9+7d4u+//xaTJ09WOzVEZhlJ1LudvHP6wv/zzz8FADF9+nSpLPOEir179xZ//fWX+Pfff8W8efNEqVKl3juhYocOHURQUJA4fPiw2LFjh/j222+Fra2tyoSKQgjx1VdfqXSIz4km79+MpPfLL78U+/fvF8uXLxcfffSRcHZ21igREkKICRMmCKVSKYoVKyZ69+6dZf+VK1eEnZ2dqFu3rggMDBQHDx4U27dvF7/++qto3rz5e58XpWMipEdySoTi4+NF6dKlRcWKFUVKSooQQogLFy6I7t27i+LFiwtTU1NRokQJ0aJFiyyjL+7fvy8GDhwoSpQoIc0R1L17d/HkyRPpmNevX4tJkyZJc6RkzGfi6+urkkRklwjFxMQICwuLHEesPHv2TIwePVqULVtWmJqaCnt7e1GrVi0xceJEab6ivCRCGfHPmDFDVK9eXVhaWgpLS0tRtWpV8eOPP2aZC0mIt1+sixYtEuXLlxempqbCw8ND7QRt2oj7559/FmXKlBFKpVJ4enqKgICALAmLEEKcP39eNGrUSFhaWuZ6HqF3qbtuRESE6NKli7C2thZFihQRXbt2VTunSU5u374tRowYISpUqCCUSqWwsLAQlSpVEn5+fioJR24TIU1el+wSISHSE6qPPvpIKJVKUa5cOeHv7y+WL1+udqTV6tWrRZ06dYS5ubmwtrYWNWrUUKkRi46OFt26dRNFixYVCoVCJY7k5GQxe/ZsUa1aNel8Dw8PMWzYMHHz5k3pOE0SoTlz5oiGDRsKR0dHYWZmJkqXLi0GDRok7t69q3LehAkThIuLizAyMnrvPELx8fFi8uTJ0vxYDg4OokWLFuL48eNqY8oQExMjrK2txcyZM1XK3/eFX69ePWFnZ6dS25GWliaCgoJEs2bNRNGiRYWZmZkoW7as+PLLL7OMwMzsr7/+Eh06dBDFihUTJiYmws7OTjRv3lwsWbJEpdYkLS1NuLm5ia+++irH55RZbt+/aWlpYubMmaJcuXLC3Nxc1K5dW/zzzz/ZjhrLKRG6ceOGNPdTSEiI2mPCw8PFwIEDpXnKihUrJho2bCh+/PHHXD83Q6cQ4v+HxBBRrikUCowcORILFiyQOxTZzJgxA5MmTUJERESeOxGTfvnqq69w4MABXLly5YNHdenSgQMH0KZNG1y5cgUeHh5yh0MyY2dpInqvjITPw8MDycnJ+OeffzBv3jx88cUXTIJIMmnSJKxevRpbtmyRJhUtiH788UcMHDiQSRABYCJERLlgaWmJ3377DXfv3kViYiJKly6N7777DpMmTZI7NCpAnJycEBQUhBcvXsgdSrZevHiBpk2bSlOFELFpjIiIiAwWJ1QkIiIig8VEiIiIiAwWEyEiIiIyWAbXWTotLQ2PHj1CkSJFCvTwTiIiInpLCIFXr17leT287BhcIvTo0aM8rRVERERE8rt//75Wp+0wuEQoY3HD+/fvw8bGRuZoiIiIKDdiY2NRqlSpLIsUfyiDS4QymsNsbGyYCBERERUy2u7Wws7SREREZLCYCBEREZHBYiJEREREBouJEBERERksJkJERERksJgIERERkcFiIkREREQGi4kQERERGSwmQkRERGSwmAgRERGRwZI1ETp8+DC8vb3h4uIChUKBbdu2vfecQ4cOoVatWjA3N0e5cuWwZMkS3QdKREREeknWRCguLg7VqlXDggULcnV8eHg4vLy80LhxY5w7dw7ff/89Ro8ejS1btug4UiIiItJHsi662r59e7Rv3z7Xxy9ZsgSlS5fG3LlzAQCenp4IDQ3F7Nmz0bVrVx1FSURERPqqUPUROnHiBNq0aaNS1rZtW4SGhiI5OVmmqIiIiEjXLl9+qpPrylojpKnIyEg4OTmplDk5OSElJQXPnz+Hs7NzlnMSExORmJgobcfGxuo8TiIiIllc3wQcnwwkvZI7Eq2JiTfFqA2NsPZkKZ1cv1AlQgCgUChUtoUQassz+Pv7Y9q0aTqPi4iIckEPv6gLlNcP5Y5Aq46Fl8IX6z7D3Rd2ABJ08hiFKhEqUaIEIiMjVcqePn0KExMTODg4qD1nwoQJ8PPzk7ZjY2NRqpRuskoiIoP3vkRHz76oCzTrknJH8EESk43Qc10PPHhhDQAookzGq8T3nJQHhSoRatCgAXbs2KFStm/fPtSuXRumpqZqz1EqlVAqlfkRHhFRwafrGhlNEp1C/kVdYJkVARpNB9y7yR3JB1ECWO5+G23brkWjRqWweHErVK06R+uPI2si9Pr1a9y6dUvaDg8Px/nz52Fvb4/SpUtjwoQJePjwIVavXg0AGD58OBYsWAA/Pz8MGTIEJ06cwPLly7F+/Xq5ngIRUcH2buKTnzUy2SU6evJFTdolhEBCQgosLN5WbLRpUx57936BFi3K4s2b1zp5XFkTodDQUDRv3lzazmjC6tevH1auXInHjx8jIiJC2l+2bFns2rULvr6+WLhwIVxcXDBv3jwOnSciys7xyUD0NfX7dFUjw0SHNBQdHY/hw3ciPj4F27f3VOn326ZNeZ0+tkJk9DY2ELGxsbC1tUVMTAxsbGzkDoeI6MO8r6kr7jEg0gCFEWD1/yNrmahQAXLwYDj69AnGw4fp7+FFi7zw5Zd1shynq+/vQtVHiIiIMrm+CdjZPXfH2rkDA8J0Gw+RBpKSUjFp0j+YPfs4Mqpk7OzMUaKEdb7GwUSIiKggyk2n5nf7+7yvTw5RAXHt2nP07r0F5869HQneokVZrFrVCa6u+dtaw0SIiKigyJz8aNqp2XsTm7qowBNCYOnSM/Dz24v4+BQAgKmpEfz9W8LXtwGMjNTPCahLTISIiPJTTjU92SU/OXVqZn8fKiQSE1Pw+eebsGPHDanM09MRQUFdUKNG1pUh8gsTISKi3NDW/Du5remxLskkh/SKUmmCIkXezus3YkRtzJrVBpaW6ucBzC9MhIiI3keTTsmaUFfTw+SH9NjChV64eTMKkyc3xaefussdDgAmQkRE6uXUX+dD599hskMG4OLFJ3j06BXatasglRUtao6TJwdnuz6oHJgIERGpk91EhOyUTJSjtDSB33//D+PHH4CVlSkuXvxSZSRYQUqCAMBI7gCIiAqkjL5ACqP0GiB7DyZBRO+RXgO0Fn5++5CUlIoXLxIwY8YRucPKEWuEiKhg0/UiodmJe5z+r5UzMOxB/j42USG0bds1DB68HVFR8VLZ2LEN8NNPLWSM6v2YCBFR/tI0scnPRULVMSsi7+MTFXBxcUnw9d2LgICzUpmzszVWr+6MVq3KyRhZ7jARIqLc00btzIckNrpaJDQ7nJGZKEehoY/g47MVN25ESWWdO3sgIMAbDg6WMkaWe0yEiEhVXib8y6vcJjYcZUVU4CQkpKBjx/V4/Pg1AMDS0hTz5rXDwIE1ClyH6JwwESKitzSZL+dDameY2BAVeubmJli0qAM6d96IOnVcEBTUBRUrOsgdlsaYCBHpsw/tj8MJ/4gok6SkVJiZGUvbnTp5IDi4Bzp0qAhTU+Mcziy4mAgR6ZN3E58PacriUHEi+n8xMQkYNWo3EhNTsHFjN5Wmr06dPGSM7MMxESLSJ9lNAgiwPw4R5cmxYxH44otg3L37EgDQocMF9OtXXdaYtImJEJE+yTwJoNX/r+bMxIaI8iA5ORXTpx/GTz8dQVqaAADY2Chhbq5fqYN+PRsiQ5XRJMZJAIlIC27disYXX2zFyZNvm9cbNSqFtWu7oEyZovIFpgNMhIgKO3UjvTgJIBHlgRACK1eex1df7UZcXDIAwNhYgalTm2H8+E9gYqJ/K3MxESIq7I5PVt229+AkgESksYSEFPTpE4zNm69KZeXL2yEoqAvq1XOVMTLdYiJEVNhlHhrPkV5ElEdKpTGSk1Ol7UGDamDu3HawtjaTMSrd0786LiJDZV2SSRAR5ZlCocCyZR1RuXIxbN78OZYt66j3SRDAGiEiIiKDdO3aczx58hpNm5aRyhwdLXHx4pcwMio8S2R8KNYIERERGRAhBJYsCUXNmkvRvftmPHnyWmW/ISVBAGuEiAqfd2ePzhgyT0T0Hk+fxmHw4O3YseMGACA+PgXTpx/GggVeMkcmHyZCRIVNdrNHc8g8EeVg9+6bGDDgLzx5EieVjRxZBzNntpYxKvkxESIqLDJqgl6k/yWndvZoIqJ3xMcn47vv9mP+/FNSWfHiVlixoiM6dHCXMbKCgYkQUUGT3Yrx7y6gaucODAjLv7iIqNC5cCESPj5bceXKM6nMy6siVqzoCCcnaxkjKziYCBEVJOpmiVaHkyYS0XvExyejTZu1ePo0vSnM3NwEs2e3xogRdVRWjzd0TISI8kt2NT2ZvVvr8+6K8VxAlYhyycLCFL/91hY+PltRrZoT1q3rikqViskdVoHDRIgoP+S2piczzhJNRBpKTU2DsfHbmXF69/4YQgh061YJSiW/8tXhq0KkSxm1QO+O8nq3picz1voQkYbi4pLg67sXyclpCAz8TGWfj09VmaIqHJgIEWnTu81f7zZ1AazpISKtCg19BB+frbhxIwoA4OVVAZ9/XlnmqAoPJkJE2pTdHD/A2w7OTIKISAtSU9Mwc+YxTJ78L1JS0gAAlpamSExMfc+ZlBkTISJN5dTpOWOWZ3Vz/DABIiItiYiIQZ8+wTh8+J5UVru2C4KCusDd3UHGyAofJkJEmsqp1icD5/ghIh3ZsOEyhg/fiZiYRACAQgF8/31jTJnSFKamxjJHV/gwESLSVEZNUOZan8w4yzMR6UB8fDKGDduJNWsuSmWlS9ti7drOaNzYTcbICjcmQkSauL7pbQdoK2dg2AN54yEig6FUmqisE9a798dYuNALRYuayxhV4Wf0/kOISHJ88tv/c5FTIspHRkYKrFz5GcqXt8PatZ0RFNSFSZAWsEaIKLeub1LtG8TmLyLSoVu3ohEV9Qb16rlKZc7ORXDt2iiYmLAeQ1v4ShLlxrszQ9t7cBQYEemEEAKBgedQvfoSdO36J6Kj41X2MwnSLr6aRDm5vgkI9My6PAZrg4hIB6Kj49G9+2YMHLgdcXHJePjwFaZN+1fusPQam8aI1MluaQyAM0MTkU4cPBiOPn2C8fDh2znKBg2qgZ9+ailjVPqPiRDRu7JbIJUzQxORDiQlpWLSpH8we/ZxCJFeZmdnjoAAb3TtWkne4AwAEyEyXNnNEP3u+mBMgIhIR65de47evbfg3LlIqaxFi7JYtaoTXF1tZIzMcDARIsOVmxmi2QxGRDry5k0ymjQJxLNnbwAApqZG8PdvCV/fBjAyUsgcneFgZ2kyXJlniLYuqfpj78EkiIh0ytLSFD/91AIA4OnpiFOnhmDs2IZMgvIZa4TIsGRuDstYIJUzRBNRPhFCQKF4m+gMHlwTQgBffFEVlpamMkZmuJgIkWHIaRQYZ4gmIh2Lj0/Gd9/thxAC8+d7SeUKhQJDh9aSMTJiIkSGQV0SZF2SC6QSkc5duBAJH5+tuHLlGQCgXbsK6NDBXeaoKAMTIdJf6prBFEaAnTtHgRGRzqWlCfz++38YP/4AkpJSAQDm5iZS52gqGJgIkX5QNxT+3WHwQHoSNCAs/+IiIoP06NEr9O+/DSEhd6SyatWcsG5dV1SqVEzGyOhdTIRIP7xvKDybwYgonwQHh2HIkB2Iinq7RtjYsQ3w008toFTya7eg4R2hwiu7pi8r57fHZCQ/bAYjIh1LSEjB6NG7ERBwVipzcSmCVas6oVWrcjJGRjlhIkSFl7paIDZ9EZFMTE2NcO3ac2m7c2cPBAR4w8HBUsao6H04oSIVTtc3vU2CMiZEzFgKg4hIBsbGRlizpjNKliyCZcu8sWVLdyZBhQBrhKhwOj757f9ZC0REMrh37yVevEhA9eolpDI3t6K4fXs0+wIVIqwRosIp8+gw1gIRUT5bv/4SqlVbgi5dNiI2NlFlH5OgwoWJEBU+1ze9HRpvXZIdoYko38TEJKBPn2D07r0VMTGJCA9/iWnT/pU7LPoAsidCixYtQtmyZWFubo5atWrhyJEjOR4fFBSEatWqwdLSEs7OzhgwYACioqLyKVqS3fVNwM7ub7e5PAYR5ZNjxyJQvfpSrF17USrr3ftjTJ7cVMao6EPJmght3LgRX3/9NSZOnIhz586hcePGaN++PSIiItQef/ToUfTt2xeDBg3ClStXsGnTJpw+fRqDBw/O58hJNpn7BgFsFiMinUtOTsXkyQfRpMlK3L37EgBgY6PE2rWdERTUBba25vIGSB9EIYQQcj14vXr1ULNmTSxevFgq8/T0RKdOneDv75/l+NmzZ2Px4sW4ffu2VDZ//nzMnDkT9+/fz9VjxsbGwtbWFjExMbCxsfnwJ0H5593aIO9NbBYjIp26fTsaPj5bcfLk25nqP/mkNNas6YwyZYrKF5gB0tX3t2w1QklJSThz5gzatGmjUt6mTRscP35c7TkNGzbEgwcPsGvXLggh8OTJE2zevBkdOnTI9nESExMRGxur8kOFVObaIHsPJkFEpFNxcUmoX3+5lAQZGyvw44/N8e+//ZgE6RHZEqHnz58jNTUVTk5OKuVOTk6IjIxUe07Dhg0RFBSEHj16wMzMDCVKlEDRokUxf/78bB/H398ftra20k+pUqW0+jwon2SeNwhgkxgR6ZyVlRkmTWoMAChf3g7Hjw/CxIlNYGwse/da0iLZ76ZCoVDZFkJkKctw9epVjB49GpMnT8aZM2ewZ88ehIeHY/jw4dlef8KECYiJiZF+ctuERgXIu01irA0iIh15t7fIV1/Vw6+/tsH588NRt25JmaIiXZJtsgNHR0cYGxtnqf15+vRpllqiDP7+/mjUqBG+/fZbAEDVqlVhZWWFxo0b48cff4Szs3OWc5RKJZRKpfafAOUfdpAmIh1LSkrFpEn/wMhIgZ9/biWVGxkp4OvbQMbISNdkqxEyMzNDrVq1EBISolIeEhKChg0bqj3nzZs3MDJSDdnY2BhA1iye9MS7TWLsIE1EWhYW9gz16y/DrFnHMXPmMRw8GC53SJSPZG0a8/Pzw7Jly7BixQqEhYXB19cXERERUlPXhAkT0LdvX+l4b29vbN26FYsXL8adO3dw7NgxjB49GnXr1oWLi4tcT4N04fomINCTTWJEpDNCCCxefBq1av2Bc+fSWydMTIxw+/YLmSOj/CTrPOA9evRAVFQUfvjhBzx+/BhVqlTBrl274ObmBgB4/PixypxC/fv3x6tXr7BgwQKMHTsWRYsWRYsWLfDLL7/I9RRIV9StLM8mMSLSkqdP4zBo0Hbs3HlDKvP0dMS6dV1V1g4j/SfrPEJy4DxCBcj1TekJT+Z1wzLEPQZEWvrK8nbu6UkQa4OISAt2776J/v3/wtOncVLZiBG1MWtWG1hamsoYGeVEV9/fXBmO5KOu1uddXFmeiLQkISEF48aFYP78U1JZsWKWWLHiM3z6qbuMkZGcmAiRfDJqghRGgFXWEX8wK8LmMCLSGmNjBf7774G07eVVEStWdISTk7WMUZHcmAhR/srcHBb3OL3MyhkY9iDn84iIPpCpqTGCgrqgYcMVmDq1KUaMqJPtvHVkOJgIUf5S1xzGFeSJSAcePXqFmJgEeHoWk8oqVnTA3btjYGVlJmNkVJDIPrM0GZjMzWHWJdOHxLP5i4i0LDg4DFWrLkbXrn/izZtklX1Mgigz1giRPNgcRkQ6EBeXBF/fvQgIOAsAiIqKxw8/HFKZLZooMyZClH+ubwJeP5Q7CiLSU6Ghj+DjsxU3bkRJZZ07e+Dbb9WvVkAEMBGi/JR5zTD2CyIiLUlNTcPMmccwefK/SElJAwBYWppi3rx2GDiwBjtEU46YCFH+yTxxIvsFEZEWRETEoE+fYBw+fE8qq1PHBUFBXVCxooOMkVFhwUSI8p91Sc4STUQf7NWrRNSu/QeePXsDAFAogO+/b4wpU5rC1NRY5uiosOCoMSIiKpSKFFHi66/rAwBKl7bFoUP98eOPLZgEkUZYI0RERIXWd981QlqawKhRdVG0qLnc4VAhxBoh0r3rm4BAz7czSRMRaSglJQ1TphzE9OmHVMqNjY0waVITJkGUZ6wRIt3JWE6DM0kT0Qe4fTsaPj5bcfLkQxgZKdCqVTk0aFBK7rBIT7BGiHTj+iZgZ/esSRBnkiaiXBJCYOXK86hefSlOnkyfg0yhAC5ceCJzZKRPWCNEupF5ziDgbQLE0WJElAvR0fEYNmwnNm++KpWVL2+HoKAuqFfPVcbISN8wESLdyDxnkPcmJkBElGsHD4ajT59gPHz49vfIoEE1MHduO1hbc50w0i4mQqRbnDOIiHIpKSkV//vfP5g16ziESC+zszNHQIA3unatJG9wpLeYCBERUYGQliawe/ctKQlq0aIsVq3qBFdXG3kDI73GztJERFQgmJubYN26rrCxUWL27NYICenDJIh0jjVCREQki6dP4/DqVSLKl7eXyqpUKY57977mvECUb1gjRNrFyROJKBd2776Jjz9ejG7dNiExMUVlH5Mgyk9MhEi7MiZQFGnp25w8kYgyiY9PxujRu+HltQ5Pn8bh/PlI/PTTEbnDIgPGpjHSroxh8wojwM6dkycSkeTChUj4+GzFlSvPpDIvr4oYObKOjFGRoWMiRLph5QwMCJM7CiIqANLSBH7//T+MH38ASUmpANI7Rs+e3RojRtSBQqGQOUIyZEyESDsy1hVj3yAiyuTRo1fo128b9u+/I5VVq+aEdeu6olKlYjJGRpSOiRBpx7uLq7JvEJHBi4lJQPXqS/Ds2RupbOzYBvjppxZQKvn1QwUDO0uTdmTuG8SFVYkIgK2tOYYOrQUAcHEpgpCQPpg9uw2TICpQ+G6kD3d9E/A6fWVo9g0iosymTGmKtDSBsWMbwMHBUu5wiLLIU41QSkoK9u/fj6VLl+LVq/SagEePHuH169daDY4KuIw5g3Z2f1vGJjEig5SamgZ//yP47bcTKuWmpsaYMaMlkyAqsDSuEbp37x7atWuHiIgIJCYmonXr1ihSpAhmzpyJhIQELFmyRBdxUkFzfZNqApSBTWJEBiciIgZ9+gTj8OF7MDU1QrNmZVCjhrPcYRHlisY1QmPGjEHt2rXx4sULWFhYSOWdO3fGgQMHtBocFWDHJ6tu23sA3pu40jyRgdmw4TKqVl2Mw4fvAQBSUtJw/Ph9maMiyj2Na4SOHj2KY8eOwczMTKXczc0NDx8+1FpgVMBldI4GmAARGaDY2ESMGrULa9ZclMpKl7bF2rWd0bixm4yREWlG40QoLS0NqampWcofPHiAIkXYP8TgWJdkEkRkYI4di8AXXwTj7t2XUlnv3h9j4UIvrhNGhY7GTWOtW7fG3LlzpW2FQoHXr19jypQp8PLy0mZsRERUgCQnp2Ly5INo0mSllATZ2Cixdm1nBAV1YRJEhZLGNUK//fYbmjdvjkqVKiEhIQG9e/fGzZs34ejoiPXr1+siRipoMg+XJyKDkZSUio0bryAtTQAAPvmkNNas6YwyZYrKGxjRB9A4EXJxccH58+exYcMGnDlzBmlpaRg0aBB8fHxUOk+THsvcUZrD5YkMhpWVGYKCuqBJk0BMnNgY48d/AmNjzstLhZtCCCE0OeHw4cNo2LAhTExUc6iUlBQcP34cTZo00WqA2hYbGwtbW1vExMTAxsZG7nAKp6Wub2uE2FGaSG9FR8cjLi4JpUrZqpQ/fRqH4sWtZIqKDJWuvr81TuWbN2+O6OjoLOUxMTFo3ry5VoKiAixzsxg7ShPprYMHw1G16mJ0774ZKSlpKvuYBJE+0TgREkJAoVBkKY+KioKVFT8ceo/NYkR6LSkpFePGhaBly9V4+PAV/vvvAX755ajcYRHpTK77CHXp0gVA+iix/v37Q6lUSvtSU1Nx8eJFNGzYUPsRUsGSef4gziJNpFfCwp7Bx2crzp2LlMpatCiLfv2qyxcUkY7lOhGytU1vIxZCoEiRIiodo83MzFC/fn0MGTJE+xFSwcRmMSK9IYTA0qVn4Oe3F/HxKQAAU1MjzJjREn5+DWBklLUVgEhf5DoRCgwMBACUKVMG33zzDZvBDBGHzRPpnadP4zB48Hbs2HFDKvP0dERQUBeuF0YGQePh81OmTNFFHFSQXd+U3jco+trbMvYPIir0Xr5MQLVqSxAZ+VoqGzGiNmbNagNLS1MZIyPKPxonQgCwefNm/Pnnn4iIiEBSUpLKvrNnz2olMCpA3k2CAPYPItIDRYuao2fPypg79ySKFbPEihWf4dNP3eUOiyhfaTxqbN68eRgwYACKFy+Oc+fOoW7dunBwcMCdO3fQvn17XcRIcrq+6W0SpDDiKvNEesbfvxVGj66LS5e+ZBJEBknjCRU9PDwwZcoU9OrVC0WKFMGFCxdQrlw5TJ48GdHR0ViwYIGuYtUKTqiogeubgJ3d327bewADwuSLh4jyLC1N4Pff/4OVlRmGDq0ldzhEGiswEypGRERIw+QtLCzw6lX6cOo+ffpwrTF9k3nOIIDNYUSF1KNHr9Cu3Vr4+e3DmDF7EBb2TO6QiAoMjROhEiVKICoqCgDg5uaG//77DwAQHh4ODSuXqKDLPGcQm8OICqXg4DBUrboYISF3AAAJCSnS/4koD52lW7RogR07dqBmzZoYNGgQfH19sXnzZoSGhkqTLpKe4ZxBRIVOXFwSfH33IiDg7QAWF5ciWLWqE1q1KidjZEQFi8aJ0B9//IG0tPR1Z4YPHw57e3scPXoU3t7eGD58uNYDJCIizYSGPoKPz1bcuBEllXXu7IGAAG84OFjKGBlRwaNxImRkZAQjo7ctat27d0f37ukdah8+fIiSJUtqLzoiIsq11NQ0zJx5DJMn/ystlGppaYp589ph4MAaateJJDJ0GvcRUicyMhJfffUVKlSooI3LERFRHsTFJWPp0jNSElSnjgvOnx+GQYNqMgkiykauE6GXL1/Cx8cHxYoVg4uLC+bNm4e0tDRMnjwZ5cqVw3///YcVK1boMlYiIsqBjY0Sa9Z0hqmpESZObIxjxwaiYkUHucMiKtBy3TT2/fff4/Dhw+jXrx/27NkDX19f7NmzBwkJCdi9ezeaNm2qyzgpv2Qsp5H0Coh7LHc0RJSD2NhEvHmTjBIlrKWyxo3dcPv2aJQqZStjZESFR65rhP7++28EBgZi9uzZ2L59O4QQcHd3xz///MMkSJ9kLKfx+iEg0qvXua4YUcFz7FgEqlVbgt69tyAtTXXqEiZBRLmX60To0aNHqFSpEgCgXLlyMDc3x+DBg3UWGOWj65uAQE9gqSvw4v9XoFYYpQ+bt/fgRIpEBUhyciomTz6IJk1W4u7dlzh48C5+++2E3GERFVq5bhpLS0uDqenb1YiNjY1hZWWlk6Aon6lbVNXOnctpEBUwt25F44svtuLkyYdS2SeflEbXrpVkjIqocMt1IiSEQP/+/aFUKgEACQkJGD58eJZkaOvWrdqNkHQvYwZphRFg5ZzeFMZaIKICQwiBlSvP46uvdiMuLhkAYGyswLRpzTB+/CcwNtbKAGAig5TrT0+/fv1QvHhx2NrawtbWFl988QVcXFyk7YwfTS1atAhly5aFubk5atWqhSNHjuR4fGJiIiZOnAg3NzcolUqUL1+eo9U+xPVN6f2BgPQkaNiD9JogziRNVCBER8eje/fNGDhwu5QElS9vh+PHB2HixCZMgog+UK5rhAIDA7X+4Bs3bsTXX3+NRYsWoVGjRli6dCnat2+Pq1evonTp0mrP6d69O548eYLly5ejQoUKePr0KVJSUrQem97LGB2WuUmMnaKJCpQXL+JRrdoSPHgQK5UNGlQDc+e2g7W1mYyREekPhZBxpdR69eqhZs2aWLx4sVTm6emJTp06wd/fP8vxe/bsQc+ePXHnzh3Y29vn6TFjY2Nha2uLmJgY2NjY5Dn2Qu36JmBn96zlXFiVqMAZNmwH/vjjLOzszBEQ4M3+QGSwdPX9LVudalJSEs6cOYM2bdqolLdp0wbHjx9Xe8727dtRu3ZtzJw5EyVLloS7uzu++eYbxMfH50fI+uP4ZNVtew8mQUQF1K+/tsWgQTVw8eKXTIKIdEDjtca05fnz50hNTYWTk5NKuZOTEyIjI9Wec+fOHRw9ehTm5uYIDg7G8+fPMWLECERHR2fbTygxMRGJiYnSdmxsrNrjDMb1TarNYUyAiAoEIQSWLj0Da2szfPFFVancysoMy5Z1lDEyIv0mWyKU4d31b4QQ2a6Jk5aWBoVCgaCgIKlj9q+//opu3bph4cKFsLCwyHKOv78/pk2bpv3AC5PMs0W/fjvsFvYeTIKICoCnT+MwePB27NhxA9bWZmjQwBXly+et+Z+INCNb05ijoyOMjY2z1P48ffo0Sy1RBmdnZ5QsWVJldJqnpyeEEHjw4IHacyZMmICYmBjp5/79+9p7EoVF5tmiM+MQeSLZ7d59E1WrLsaOHemTmb5+nYSdO2/IHBWR4chTIrRmzRo0atQILi4uuHfvHgBg7ty5+Ouvv3J9DTMzM9SqVQshISEq5SEhIWjYsKHacxo1aoRHjx7h9evXUtmNGzdgZGQEV1dXtecolUrY2Nio/BiczPMEZcwWzSYxIlnFxydj9Ojd8PJahydP4gAAxYpZYseOXhgzpr7M0REZDo0TocWLF8PPzw9eXl54+fIlUlNTAQBFixbF3LlzNbqWn58fli1bhhUrViAsLAy+vr6IiIjA8OHDAaTX5vTt21c6vnfv3nBwcMCAAQNw9epVHD58GN9++y0GDhyotlnM4GUsnZGxeCrnCSIqEC5efII6dQIwf/4pqczLqyIuXfoSn37qLmNkRIZH40Ro/vz5CAgIwMSJE2FsbCyV165dG5cuXdLoWj169MDcuXPxww8/oHr16jh8+DB27doFNzc3AMDjx48REREhHW9tbY2QkBC8fPkStWvXho+PD7y9vTFv3jxNn4ZhyGgS4+KpRAVCWprAb7+dQJ06Abhy5RkAwNzcBAsWtMfOnb3g5GT9nisQkbZpPI+QhYUFrl27Bjc3NxQpUgQXLlxAuXLlcPPmTVStWrXAD2U3qHmElrqm9wtSGKWvHdZoOmuCiGT04kU8KldehMeP05v3q1Z1wrp1XVC5cnGZIyMq+ArMPEJly5bF+fPns5Tv3r1bWp2eChgrZzaHERUAdnYWWLWqE4yMFBg7tgFOnRrMJIhIZhoPn//2228xcuRIJCQkQAiBU6dOYf369fD398eyZct0ESMRUaEUF5eEhIQUODhYSmWtW5fH9eujUKECh8cTFQQaJ0IDBgxASkoKxo0bhzdv3qB3794oWbIkfv/9d/Ts2VMXMVJeZF5MlYjyXWjoI/j4bEWFCvbYubOXyvxoTIKICo4PWmvs+fPnSEtLQ/Hihadq12D6CAV6vp1B2t4jvWmMiHQuNTUNM2cew+TJ/yIlJX2gwsKFXhgxoo7MkREVbgWmj9C0adNw+/ZtAOmTIhamJMggZAyZf5FpQjZOnEiULyIiYtCixWp8//0/UhJUp44LWrcuJ3NkRJQdjROhLVu2wN3dHfXr18eCBQvw7NkzXcRFmspIgHZ2Vx0yz2U0iPLFhg2XUbXqYhw+nD7JrJGRAhMnNsaxYwNRsaKDzNERUXY0ToQuXryIixcvokWLFvj1119RsmRJeHl5Yd26dXjz5o0uYqTcyJgzKDN7D9YGEelYbGwi+vYNRq9eWxATk77Ac+nStvj333748ccWMDU1fs8ViEhOH9RHCACOHTuGdevWYdOmTUhISCjwq7vrbR8hzhlElO+iot6gTp0AhIe/lMp69/4YCxd6oWhRc/kCI9JDuvr+/uDV562srGBhYQEzMzO8evVKGzHRh8iYM4iIdM7BwRKNGpVGePhL2NgosWiRF3x8qsodFhFpIE+JUHh4ONatW4egoCDcuHEDTZo0wdSpU/H5559rOz4iogJtwYL2SE1Nw4wZLVGmTFG5wyEiDWmcCDVo0ACnTp3Cxx9/jAEDBkjzCJGMOGcQkc4JIbBq1QXY2CjRpYunVG5ra45167rKGBkRfQiNE6HmzZtj2bJlqFy5si7iobw4Pvnt/7mwKpHWRUfHY9iwndi8+SqKFjVHnTouKFXKVu6wiEgLNB41NmPGDCZBBU1Spr5ZHCVGpFUHD4ajatXF2Lz5KgDg5csE6f9EVPjlqkbIz88P06dPh5WVFfz8/HI89tdff9VKYJRLmZvFrEtypBiRliQlpWLSpH8we/ZxZIyttbMzR0CAN7p25QLTRPoiV4nQuXPnkJycLP2fChA2ixFp3bVrz9G79xacOxcplbVoURarVnWCq6seTbtBRLlLhA4ePKj2/yST65vSE6CkV0Dc47flbBYj+iBCCCxdegZ+fnsRH58CADA1NYK/f0v4+jaAkZHiPVcgosJG4z5CAwcOVDtfUFxcHAYOHKiVoOg9MmaRfv2QS2kQaVF0dDz+97+DUhLk6emIU6eGYOzYhkyCiPSUxonQqlWrEB8fn6U8Pj4eq1ev1kpQ9B4ZnaMVRun9griUBpFWODhYYtkybwDAiBG1ERo6FNWrl5A5KiLSpVwPn4+NjYUQAkIIvHr1Cubmb6ePT01Nxa5du7gSfX6zcgaGPZA7CqJCKz4+GUlJqbC1ffv77LPPPHDx4nB8/LGTjJERUX7JdSJUtGhRKBQKKBQKuLu7Z9mvUCgwbdo0rQZHanDyRCKtuHjxCXr33gJPz2L4889uUCjeNn0xCSIyHLlOhA4ePAghBFq0aIEtW7bA3t5e2mdmZgY3Nze4uLjoJEj6f9c3ATu7v93mKDEijaWlCfz++38YP/4AkpJSceXKM6xadQH9+1eXOzQikkGuE6GmTZsCSF9nrHTp0ip/PVE+yTxUHmC/ICINPXr0Cv37b0NIyB2prFo1J9Sty2WCiAxVrhKhixcvokqVKjAyMkJMTAwuXbqU7bFVq3LlZZ3JPIO09yaOEiPSQHBwGIYM2YGoqLeDPcaObYCffmoBpTJP608TkR7I1ae/evXqiIyMRPHixVG9enUoFAqIjKlWM1EoFEhNTdV6kPQOziBNlGtxcUnw9d2LgICzUpmLSxGsWtUJrVqVkzEyIioIcpUIhYeHo1ixYtL/iYgKg2fP4vDJJ4G4cSNKKuvc2QMBAd5wcLCUMTIiKihylQi5ubmp/T8RUUHm6GiJypWL4caNKFhammLevHYYOLAG+zgSkSRPEyr+/fff0va4ceNQtGhRNGzYEPfu3dNqcJQJh80TaUyhUCAgwBsdO36E8+eHYdCgmkyCiEiFxonQjBkzYGFhAQA4ceIEFixYgJkzZ8LR0RG+vr5aD5D+HxdXJXqvDRsuY/fumyplDg6W+OuvnqhY0UGmqIioINN4qMT9+/dRoUIFAMC2bdvQrVs3DB06FI0aNUKzZs20HR9lyDxijMPmiVTExiZi1KhdWLPmIooVs8SlS1/Cycla7rCIqBDQuEbI2toaUVHpHQ/37duHVq1aAQDMzc3VrkFGWsYRY0Qqjh2LQLVqS7BmzUUAwLNnbxAUlP0UH0REmWlcI9S6dWsMHjwYNWrUwI0bN9ChQwcAwJUrV1CmTBltx0dEpFZyciqmTz+Mn346grS09Ok8bGyUWLTICz4+nM+MiHJH4xqhhQsXokGDBnj27Bm2bNkCB4f0dvczZ86gV69eWg+QwI7SRO+4dSsajRsHYvr0w1IS9MknpXHhwnAmQUSkEYVQNzOiHouNjYWtrS1iYmJgY2Mjdzi5E+gJRF9L/7+9BzAgTN54iGQihMDKlefx1Ve7EReXDAAwNlZg2rRmGD/+Exgba/y3HREVErr6/s7TvPIvX77E8uXLERYWBoVCAU9PTwwaNAi2trZaC4wyYUdpIgDp/X98ffdKSVD58nYICuqCevVcZY6MiAorjf98Cg0NRfny5fHbb78hOjoaz58/x2+//Yby5cvj7Nmz778A5R07SpOBK17cCkuWfAoAGDSoBs6fH84kiIg+iMY1Qr6+vujYsSMCAgJgYpJ+ekpKCgYPHoyvv/4ahw8f1nqQRGSYkpJSkZycCisrM6msZ88qKFfOjivGE5FW5KlG6LvvvpOSIAAwMTHBuHHjEBoaqtXgiMhwXbv2HA0aLMfIkbuy7GMSRETaonEiZGNjg4iIiCzl9+/fR5EinPGYiD6MEAJLloSiZs2lOHv2MVatuoA//7wid1hEpKc0bhrr0aMHBg0ahNmzZ6Nhw4ZQKBQ4evQovv32Ww6fJ6IP8uxZHAYN2o4dO25IZZ6ejqhY0V7GqIhIn2mcCM2ePRsKhQJ9+/ZFSkoKAMDU1BRffvklfv75Z60HaNCub0pfYyzusdyREOncnj230L//Njx5EieVjRhRG7NmtYGlpamMkRGRPsvzPEJv3rzB7du3IYRAhQoVYGlpqe3YdKLQzCN0fROws7tqGecQIj0UH5+M8eP3Y968U1JZsWKWWLHiM3z6qbuMkRFRQSL7PEJv3rzBt99+i23btiE5ORmtWrXCvHnz4OjoqLVgKJPMq80D6UkQ5xAiPfP0aRxatlyNy5efSmVeXhWxYkVHLppKRPki152lp0yZgpUrV6JDhw7o2bMnQkJC8OWXX+oyNsOWeRJF703pNUGcQ4j0jKOjJUqWTB9kYW5uggUL2mPnzl5Mgogo3+S6Rmjr1q1Yvnw5evbsCQD44osv0KhRI6SmpsLY2FhnARo8TqJIeszISIHAwM/Qt+82/P57O1SqVEzukIjIwOS6Ruj+/fto3LixtF23bl2YmJjg0aNHOgnMoHGRVdJT27Zdw7//3lUpc3YugpCQPkyCiEgWuU6EUlNTYWZmplJmYmIijRwjLXm3k7QZ52aiwi8uLglDh+5A584b8cUXWxEdHS93SEREADRoGhNCoH///lAqlVJZQkIChg8fDisrK6ls69at2o3Q0LzbSZodpKmQCw19BB+frbhxIwoA8PDhK6xceR5+fg1kjoyISINEqF+/flnKvvjiC60GQ8jaSZr9g6iQSk1Nw8yZxzB58r9ISUkDAFhammLevHYYOLCGzNEREaXLdSIUGBioyzgIUO0bxE7SVIhFRMSgT59gHD58TyqrXdsFQUFd4O7uIGNkRESqNJ5ZmnQoc7MY+wZRIbVhw2UMH74TMTGJAACFAvj++8aYMqUpTE05wpSIChYmQgVJ5mYx9g2iQigy8jUGD96OuLhkAEDp0rZYu7YzGjd2kzkyIiL1NF59nnSEzWKkB0qUsMbvv7cDAPTqVQUXLgxnEkREBRprhAoCDpmnQio5ORWpqQLm5m9/lQwcWAPlytmhefOyMkZGRJQ7rBEqCDhkngqhW7ei0bhxIMaO3atSrlAomAQRUaGRp0RozZo1aNSoEVxcXHDvXvqokLlz5+Kvv/7SanAGg0PmqRARQiAw8ByqV1+CkycfYtGiUOzceUPusIiI8kTjRGjx4sXw8/ODl5cXXr58idTUVABA0aJFMXfuXG3HZ1jYN4gKuOjoeHTvvhkDB77tEF2+vB2KF7d6z5lERAWTxonQ/PnzERAQgIkTJ6ostlq7dm1cunRJq8ERUcFx8GA4qlZdjM2br0plgwbVwPnzw1G3bkkZIyMiyjuNO0uHh4ejRo2ss8IqlUrExcVpJSgiKjiSklIxadI/mD37OIRIL7OzM0dAgDe6dq0kb3BERB9I40SobNmyOH/+PNzcVIfE7t69G5Uq8ZcikT55+jQO7dqtxblzkVJZy5ZlsWpVJ5QsaSNjZERE2qFxIvTtt99i5MiRSEhIgBACp06dwvr16+Hv749ly5bpIkYikomDgwWKFElfaNnU1Aj+/i3h69sARkYKmSMjItIOjfsIDRgwAFOmTMG4cePw5s0b9O7dG0uWLMHvv/+Onj17ahzAokWLULZsWZibm6NWrVo4cuRIrs47duwYTExMUL16dY0fk4hyx9jYCGvWdEbDhqVw6tQQjB3bkEkQEekVhRAZrf6ae/78OdLS0lC8ePE8nb9x40b06dMHixYtQqNGjbB06VIsW7YMV69eRenSpbM9LyYmBjVr1kSFChXw5MkTnD9/PtePGRsbC1tbW8TExMDGRuaq/eub0ucQenEDEGnpo8aGPZA3JjJou3ffhJ2dBerXd1UpF0JAoWACRETy0dX39wclQh+qXr16qFmzJhYvXiyVeXp6olOnTvD398/2vJ49e6JixYowNjbGtm3bCm8iFOgJRF97u23vAQwIky8eMljx8cn47rv9mD//FMqWLYrz54fDxkYpd1hERBJdfX/nqbN0Tn8Z3rlzJ1fXSUpKwpkzZzB+/HiV8jZt2uD48ePZnhcYGIjbt29j7dq1+PHHH9/7OImJiUhMTJS2Y2NjcxVfvsiYSFFhBNi5c0ZpksWFC5Hw8dmKK1eeAQDCw19i+fKz8PVtIHNkRES6p3Ei9PXXX6tsJycn49y5c9izZw++/fbbXF/n+fPnSE1NhZOTk0q5k5MTIiMj1Z5z8+ZNjB8/HkeOHIGJSe5C9/f3x7Rp03IdlyysnFkTRPkuLU3g99//w/jxB5CUlD4xqrm5CebMaYMvv6wtc3RERPlD40RozJgxassXLlyI0NBQjQN4t3Ypu74Iqamp6N27N6ZNmwZ3d/dcX3/ChAnw8/OTtmNjY1GqVCmN49S6zKvNE+WzR49eoX//bQgJeVuDW62aE9at64pKlYrJGBkRUf7S2qKr7du3x5YtW3J9vKOjI4yNjbPU/jx9+jRLLREAvHr1CqGhoRg1ahRMTExgYmKCH374ARcuXICJiQn++ecftY+jVCphY2Oj8lMgZF5olavNUz4KDg5D1aqLVZKgsWMb4OTJwUyCiMjgaFwjlJ3NmzfD3t4+18ebmZmhVq1aCAkJQefOnaXykJAQfPbZZ1mOt7GxybKEx6JFi/DPP/9g8+bNKFu2kK12nXmhVfYNonzy6NEr9Oq1BYmJ6U1hLi5FsGpVJ7RqVU7myIiI5KFxIlSjRg2VpishBCIjI/Hs2TMsWrRIo2v5+fmhT58+qF27Nho0aIA//vgDERERGD58OID0Zq2HDx9i9erVMDIyQpUqVVTOL168OMzNzbOUFypcaJXykYtLEcya1RqjR+9B584eCAjwhoODpdxhERHJRuNEqFOnTirbRkZGKFasGJo1awYPDw+NrtWjRw9ERUXhhx9+wOPHj1GlShXs2rVLWr7j8ePHiIiI0DREIvp/qalpSEsTMDV9u0DyqFF1Ua6cHby8KnJuICIyeBrNI5SSkoKgoCC0bdsWJUqU0GVcOlNg5hFa6preWZqTKJKORETEoE+fYNSrVxIzZ7aWOxwiog+iq+9vjTpLm5iY4Msvv1SZl4eICp4NGy6jatXFOHz4HmbNOo4DB3I3vxcRkaHReNRYvXr1cO7cOV3EQkQfKDY2EX37BqNXry2IiUn/g6V0aVuYm2ttXAQRkV7R+LfjiBEjMHbsWDx48AC1atWClZWVyv6qVatqLTgiyr1jxyLwxRfBuHv3pVTWu/fHWLjQC0WLmssXGBFRAZbrRGjgwIGYO3cuevToAQAYPXq0tE+hUEgTIaampmo/SiLKVnJyKqZPP4yffjqCtLT0Ln82NkosWuQFHx/+YUJElJNcJ0KrVq3Czz//jPDwcF3GQ0QaePo0Dh07rsfJk29nKf/kk9JYs6YzypQpKl9gRESFRK4ToYzBZRlD2ymPrm9Kn1U67rHckZAesLMzR8a4T2NjBaZNa4bx4z+BsbHWJo0nItJrGv225JwjWnB8MhB9DRBp6dtcXoM+gKmpMYKCuqB69RI4fnwQJk5swiSIiEgDGnWWdnd3f28yFB0d/UEB6b2MpTUURoCdO5fXII0cPBgOOzsLVK/+dh6vChXscfbsUP6hQkSUBxolQtOmTYOtra2uYjEsVs7AgDC5o6BCIikpFZMm/YPZs4/jo48ccebMUFhamkr7mQQREeWNRolQz549Ubx4cV3FQkRqXLv2HL17b8G5c5HSdkDAGYwZU1/myIiICr9cdybgX5xE+UsIgSVLQlGz5lIpCTI1NcLs2a3x1Vf1ZI6OiEg/aDxqjD7A9U3p64sRvcfTp3EYPHg7duy4IZV5ejpi3bquKv2DiIjow+Q6EUpLS9NlHIbh+OS3/+doMcrG7t03MWDAX3jyJE4qGzGiNmbNaqPSL4iIiD4cFyDKTxkjxgCOFiO1HjyIxWefbUBycvofHsWKWWLFis/w6afuMkdGRKSfOOGIrl3fBAR6Aktd306iaF0ScO8mb1xUILm62uCHH5oDANq3r4BLl75kEkREpEOsEdK1jAkUM2OzGP2/tDQBIYTKJIjfftsQ5cvboVu3ShykQESkY6wR0rXMEyhalwTsPdgsRgCAR49eoV27tZg+/bBKubGxET7/vDKTICKifMAaofxi5QwMeyB3FFRABAeHYciQHYiKiseBA+Fo06Y8GjYsJXdYREQGhzVCupLRN4iLq1ImcXFJGDp0B7p0+RNRUfEAACcnKyQnp8ocGRGRYWKNkK682zeI/YIMXmjoI/j4bMWNG1FSWefOHggI8IaDg6WMkRERGS4mQrrCxVXp/6WmpmHmzGOYPPlfpKSkD4u3tDTFvHntMHBgDfYFIiKSERMhXePiqgbt6dM4fP75Jhw+fE8qq1PHBUFBXVCxooOMkREREcA+QkQ6ZWOjxMuXCQAAhQKYOLExjh0byCSIiKiAYCKkbewkTZmYm5tg3bou+OgjBxw61B8//tgCpqbGcodFRET/j01j2sZO0gbt2LEI2NlZoFKlYlJZ5crFceXKCJVJE4mIqGDgb2Zty9xJmpMnGozk5FRMnnwQTZqsRO/eW5CYmKKyn0kQEVHBxN/O2nR9E/D6Yfr/MzpJc00xvXf7djQaNw7E9OmHkZYmcOHCE/zxxxm5wyIiolxg05g2HZ/89v9sEtN7QgisWnUBX321G69fJwEAjI0VmDatGUaMqCNvcERElCtMhLTh+qb0JOjFjbdlbBLTa9HR8Rg2bCc2b74qlZUvb4d167qibt2SMkZGRESaYCL0oa5vAnZ2Vy2z92CTmB77559w9O0bjIcPX0llgwbVwNy57WBtbSZjZEREpCkmQh8qc3MYwA7Sei4iIgZt266VZoi2szNHQIA3unatJHNkRESUF+ws/SGub1IdKu+9iR2k9Vzp0raYMOETAECLFmVx8eKXTIKIiAox1gh9iMy1QWwO00tCCAgBGBm9XQ/sf/9rgvLl7dCnTzWVciIiKnxYI/Qhkt72EWFzmP55+jQOn322AXPmHFcpNzU1Rr9+1ZkEERHpAdYI5VXmOYOsS7I2SM/s3n0TAwb8hSdP4rBnzy20bFkONWs6yx0WERFpGROhvOKcQXopPj4Z3323H/Pnn5LKihY1x4sX8TJGRUREusJEKC/e7STNZjG9cOFCJHx8tuLKlWdSWfv2FRAY+BmcnKxljIyIiHSFiVBesJO0XklLE/j99/8wfvwBJCWlAkhfNX7WrNYYObIOFAr2BSIi0ldMhPKCnaT1xrNncejdeyv2778jlVWt6oR167qgcuXiMkZGRET5gaPGPgQ7SRd6lpamiIiIkbbHjm2AU6cGMwkiIjIQTIQ0lXm0GBV6VlZmWLeuC8qUKYqQkD6YPbsNlEpWlBIRGQr+xtcUR4sVaqGhj2BnZ47y5e2lslq1XHDjxiiYmhrLGBkREcmBNUKaYv+gQik1NQ3+/kfQoMFy+PhsRXJyqsp+JkFERIaJiZAmOIlioRQREYMWLVbj++//QUpKGk6efIhly87KHRYRERUAbBrTBJvFCp0NGy5j+PCdiIlJBAAoFMD33zfG4ME1ZY6MiIgKAiZCmmCzWKERG5uIUaN2Yc2ai1JZ6dK2WLu2Mxo3dpMxMiIiKkiYCOUFm8UKtOPH7+OLL7YiPPylVNa798dYuNALRYuayxcYEREVOEyESK/cvfsSTZuuREpKGgDAxkaJRYu84ONTVebIiIioIGJn6dzi/EGFQpkyRfHVV3UBAI0alcKFC8OZBBERUbZYI5Rb7ChdIAkhAEBlPbAZM1qiQgV7DB1aCyYmzPWJiCh7/JbILXaULnCio+PRvftmLFp0WqXc3NwEI0bUYRJERETvxRohTbGjdIFw8GA4+vQJxsOHr7Bz5w00a1aG64MREZHG+CczFSpJSakYNy4ELVuuxsOH6bV0FhYm0v+JiIg0wRohKjTCwp7Bx2crzp2LlMpatCiLVas6wdXVRsbIiIiosGIiRAWeEAJLloRi7Nh9iI9PAQCYmhrB378lfH0bwMhI8Z4rEBERqcdEiAq0qKg36N//L+zceUMq8/R0RFBQF9So4SxjZEREpA/YR4gKNBMTI1y69ETaHjGiNkJDhzIJIiIirWAiRAWara051q7tAmdna+zY0QsLF3aApaWp3GEREZGeYNMYFSgXLkTC3t4CpUrZSmWffFIad+6Mgbk5365ERKRdstcILVq0CGXLloW5uTlq1aqFI0eOZHvs1q1b0bp1axQrVgw2NjZo0KAB9u7dm4/Rkq6kpQn89tsJ1K27DH36BCM1NU1lP5MgIiLSBVkToY0bN+Lrr7/GxIkTce7cOTRu3Bjt27dHRESE2uMPHz6M1q1bY9euXThz5gyaN28Ob29vnDt3Lp8jJ2169OgV2rVbCz+/fUhKSsWhQ/ewYgXvKRER6Z5CZCzWJIN69eqhZs2aWLx4sVTm6emJTp06wd/fP1fXqFy5Mnr06IHJkye//2AAsbGxsLW1RUxMDGxsNJh7Zqlr+qKr1iWBYQ9yfx7lKDg4DEOG7EBUVLxUNnZsA/z0UwsolawFIiKidHn+/n4P2b5pkpKScObMGYwfP16lvE2bNjh+/HiurpGWloZXr17B3t4+22MSExORmJgobcfGxmoeLFee17q4uCT4+u5FQMBZqczFpQhWreqEVq3KyRgZEREZEtmaxp4/f47U1FQ4OTmplDs5OSEyMjKbs1TNmTMHcXFx6N69e7bH+Pv7w9bWVvopVaqU5sFy5XmtCg19hJo1/1BJgrp08cTFi8OZBBERUb6SvbO0QqE6K7AQIkuZOuvXr8fUqVOxceNGFC+e/WKbEyZMQExMjPRz//59zQK8vgmIvvZ2myvPf5A7d16gQYPluHEjCgBgZWWK5cs7YvPmz+HgYClzdEREZGhkS4QcHR1hbGycpfbn6dOnWWqJ3rVx40YMGjQIf/75J1q1apXjsUqlEjY2Nio/GslcG2TvwZXnP1C5cnYYNKgGAKBOHRecOzcMAwfWyFXyS0REpG2yJUJmZmaoVasWQkJCVMpDQkLQsGHDbM9bv349+vfvj3Xr1qFDhw66DhNIyrSqOWuDtGLOnDaYPbs1jh0biIoVHeQOh4iIDJisTWN+fn5YtmwZVqxYgbCwMPj6+iIiIgLDhw8HkN6s1bdvX+n49evXo2/fvpgzZw7q16+PyMhIREZGIiYmRvfBWpdkbZCGYmMT0bdvMAIDVYfCW1mZYezYhjA1NZYpMiIionSyjk/u0aMHoqKi8MMPP+Dx48eoUqUKdu3aBTc3NwDA48ePVeYUWrp0KVJSUjBy5EiMHDlSKu/Xrx9Wrlyp/QA5WizPjh+/jy++2Irw8JcIDr6Gxo3dUKFC9qP7iIiI5CDrPEJy0GgegkDPtx2l7T2AAWG6D7CQS0lJw/Tph/Djj0eQlpb+1rKxUWLjxm5o166CzNEREVFhpXfzCBV4HC2msdu3o+HjsxUnT76tRfvkk9JYs6YzypQpKl9gRERE2WAilB2OFss1IQRWrbqAr77ajdevkwAAxsYKTJvWDOPHfwJjY9lnaSAiIlKLiVB2OFosV168iMfQoTuxefNVqax8eTusW9cVdeuWlDEyIiKi92MipE7mTtIcLZajtDSB48ffTlI5aFANzJ3bDtbWZjJGRURElDtss3jX9U3AzkxLdnBJjRw5OFhi1apOcHCwwObNn2PZso5MgoiIqNBgjdC7jr+zij2bxVSEhT2Dvb0FnJyspbJWrcohPHwMihRRyhgZERGR5lgj9K7MfYO8N7FZ7P8JIbBkSShq1foDAwb8hXdnXWASREREhREToeywb5Dk6dM4fPbZBnz55d+Ij0/B7t23sGrVBbnDIiIi+mBsGqMc7dlzC/37b8OTJ3FS2YgRtdG9e2UZoyIiItIOJkKkVnx8MsaP3495805JZcWKWWLFis/w6afuMkZGRESkPUyEKItLl56gd++tuHz5qVTm5VURK1Z0VOkkTUREVNgxESIVt25Fo3btACQlpQIAzM1NMHt2a4wYUQcKhULm6IiIiLSLnaUz42rzqFDBHj16pPf/qVbNCWfODMXIkXWZBBERkV5ijVBmmecQMuCJFBcs8ELFivYYN64RlEq+RYiISH+xRigzA1tfLC4uCUOH7sDGjZdVym1slPjf/5oyCSIiIr3Hbzp1DGAOodDQR/Dx2YobN6KwadNVNGxYCqVK2codFhERUb5ijZCBSU1Ng7//ETRosBw3bkQBAJKSUnHx4hOZIyMiIsp/rBEyIBERMejTJxiHD9+TyurUcUFQUBdUrOggY2RERETyYCJkIDZsuIzhw3ciJiYRAKBQAN9/3xhTpjSFqamxzNERERHJg4mQnouNTcSoUbuwZs1Fqax0aVusXdsZjRu7yRgZERGR/JgI6bk3b5Kxe/ctabtXrypYtKgDihY1lzEqIiKigoGdpfVciRLWWL68I2xslFi7tjPWrevKJIiIiOj/sUYog57MKn3rVjTs7Mzh4GAplXXs+BHCw8fA3t5CxsiIiIgKHtYIZSjks0oLIRAYeA7Vqy/BsGE7IYRQ2c8kiIiIKCsmQhkK8azS0dHx6N59MwYO3I64uGRs2RKG9esvv/9EIiIiA8emsXcVslmlDx4MR58+wXj48G0iN2hQDXTs+JGMURERERUOhpsIra0NGL95ux33WL5Y8iApKRWTJv2D2bOPI6MVzM7OHAEB3ujatZK8wRERERUShpsIvbgJqBs8VQj6B1279hy9e2/BuXORUlmLFmWxalUnuLrayBgZERFR4WK4iRAAKIwAK+e322ZFCnz/oOvXn6NmzaWIj08BAJiaGsHfvyV8fRvAyEghc3RERESFi2EnQlbOwLAHckehEXd3B7RvXxFbt4bB09MR69Z1RfXqJeQOi4iIqFAy7ESoEFIoFPjjj0/h7m6P//2vKSwtTeUOiYiIqNBiIlSAxccn47vv9qN163Lw9n47CszBwRL+/q1kjIzIMKWmpiI5OVnuMIj0lqmpKYyN83chcCZCBdSFC5Hw8dmKK1eeYf36y7h06UuUKGEtd1hEBuv169d48OBBlslKiUh7FAoFXF1dYW2df993TIQKmLQ0gd9//w/jxx9AUlIqAOD16ySEhj7Cp5+6yxwdkWFKTU3FgwcPYGlpiWLFikGh4MAEIm0TQuDZs2d48OABKlasmG81Q0yECpBHj16hf/9tCAm5I5VVq+aEdeu6olKlYjJGRmTYkpOTIYRAsWLFYGHB5WqIdKVYsWK4e/cukpOTmQgZmuDgMAwZsgNRUfFS2dixDfDTTy2gVPI2ERUErAki0i05PmP8hpXZ69dJ8PXdg2XLzkllLi5FsGpVJ7RqVU7GyIiIiPQfEyGZvXgRj02brkrbnTt7ICDAGw4OljJGRUREZBi4+rzMSpWyxdKln8LKyhTLlnljy5buTIKIiGQWFRWF4sWL4+7du3KHojcuXboEV1dXxMXFyR2KCiZC+SwiIgaxsYkqZT16VMGtW6MxaFBN9kEgIq3p378/FAoFFAoFTExMULp0aXz55Zd48eJFlmOPHz8OLy8v2NnZwdzcHB9//DHmzJmD1NTULMcePHgQXl5ecHBwgKWlJSpVqoSxY8fi4cOH+fG08oW/vz+8vb1RpkyZLPvatGkDY2Nj/Pfff1n2NWvWDF9//XWW8m3btmX5/Z6UlISZM2eiWrVqsLS0hKOjIxo1aoTAwECdzlcVEREBb29vWFlZwdHREaNHj0ZSUlKO50RGRqJPnz4oUaIErKysULNmTWzevDnLcX///Tfq1asHCwsLODo6okuXLtK+jz/+GHXr1sVvv/2m9ef0IZgI5aMNGy6jatXF+Oqr3Vn2cY4gItKFdu3a4fHjx7h79y6WLVuGHTt2YMSIESrHBAcHo2nTpnB1dcXBgwdx7do1jBkzBj/99BN69uypMnfS0qVL0apVK5QoUQJbtmzB1atXsWTJEsTExGDOnDn59rze98X9IeLj47F8+XIMHjw4y76IiAicOHECo0aNwvLly/P8GElJSWjbti1+/vlnDB06FMePH8epU6cwcuRIzJ8/H1euXPmQp5Ct1NRUdOjQAXFxcTh69Cg2bNiALVu2YOzYsTme16dPH1y/fh3bt2/HpUuX0KVLF/To0QPnzr3t37plyxb06dMHAwYMwIULF3Ds2DH07t1b5ToDBgzA4sWL1SbYshEGJiYmRgAQMT9CiCUl8+kxE0SfPlsFMFX62bz5Sr48NhF9uPj4eHH16lURHx8vdyga6devn/jss89Uyvz8/IS9vb20/fr1a+Hg4CC6dOmS5fzt27cLAGLDhg1CCCHu378vzMzMxNdff6328V68eJFtLC9evBBDhgwRxYsXF0qlUlSuXFns2LFDCCHElClTRLVq1VSO/+2334Sbm1uW5zJjxgzh7Ows3NzcxPjx40W9evWyPNbHH38sJk+eLG2vWLFCeHh4CKVSKT766COxcOHCbOMUQogtW7YIR0dHtfumTp0qevbsKcLCwkSRIkXE69evVfY3bdpUjBkzJst5wcHBIvNX7i+//CKMjIzE2bNnsxyblJSU5brasmvXLmFkZCQePnwola1fv14olUoRExOT7XlWVlZi9erVKmX29vZi2bJlQgghkpOTRcmSJaXt7CQmJgqlUikOHDigdn9OnzXp+zuHOPOCnaV17NixCHzxRTDu3n0plfXqVQUtW3JEGFGhtrY2EBeZ/49rVQL4IjRPp965cwd79uyBqenbNQr37duHqKgofPPNN1mO9/b2hru7O9avX48ePXpg06ZNSEpKwrhx49Rev2jRomrL09LS0L59e7x69Qpr165F+fLlcfXqVY3niTlw4ABsbGwQEhIi1VL9/PPPuH37NsqXLw8AuHLlCi5duiQ12wQEBGDKlClYsGABatSogXPnzmHIkCGwsrJCv3791D7O4cOHUbt27SzlQggEBgZi4cKF8PDwgLu7O/78808MGDBAo+cBAEFBQWjVqhVq1KiRZZ+pqanKPcosIiIClSpVyvHaX3zxBZYsWaJ234kTJ1ClShW4uLhIZW3btkViYiLOnDmD5s2bqz3vk08+wcaNG9GhQwcULVoUf/75JxITE9GsWTMAwNmzZ/Hw4UMYGRmhRo0aiIyMRPXq1TF79mxUrlxZuo6ZmRmqVauGI0eOoEWLFjk+j/zCREhHkpNTMX36Yfz00xGkpaV/YG1slFi0yAs+PlVljo6IPlhcJPC64PeJ2blzJ6ytrZGamoqEhAQAwK+//irtv3HjBgDA09NT7fkeHh7SMTdv3oSNjQ2cnZ01imH//v04deoUwsLC4O6ePkN+uXKa/zFoZWWFZcuWwczMTCqrWrUq1q1bh//9738A0hOMOnXqSI8zffp0zJkzR+qrUrZsWVy9ehVLly7NNhG6e/euSqKQ+Xm8efMGbdu2BZCecCxfvjxPidDNmzelJEITLi4uOH/+fI7H2NjYZLsvMjISTk5OKmV2dnYwMzNDZGT2if3GjRvRo0cPODg4wMTEBJaWlggODpYS0Dt30icCnjp1Kn799VeUKVMGc+bMQdOmTXHjxg3Y29tL1ypZsmSB6oTOREgHbt2KxhdfbMXJk29/STZqVApr13ZBmTJF5QuMiLTHqkSheNzmzZtj8eLFePPmDZYtW4YbN27gq6++ynKcyGYNNSGE1Mk38/81cf78ebi6ukrJSV59/PHHKkkQAPj4+GDFihX43//+ByEE1q9fL3VWfvbsGe7fv49BgwZhyJAh0jkpKSmwtbXN9nHi4+Nhbm6epXz58uXo0aMHTEzSvzp79eqFb7/9FtevX8dHH32U5fic5PW1NDExQYUKFTQ+LzN1j/u+eCZNmoQXL15g//79cHR0xLZt2/D555/jyJEj+Pjjj5GWlgYAmDhxIrp27QoACAwMhKurKzZt2oRhw4ZJ17KwsMCbN28+6DloExMhLQsLe4Y6dQIQF5fe49/YWIGpU5th/PhPYGLCvulEeiOPzVP5zcrKSvrinDdvHpo3b45p06Zh+vTpACAlJ2FhYWjYsGGW869duyY1xbi7uyMmJgaPHz/WqFbofcuSGBkZZUnE1I2asrKyylLWu3dvjB8/HmfPnkV8fDzu37+Pnj17AoD05RwQEIB69eqpnJdTs5yjo2OWkXXR0dHYtm0bkpOTsXjxYqk8NTUVK1aswC+//AIgvTYmJiYmyzVfvnypUlPj7u6OsLCwbGPIzoc2jZUoUQInT55UKXvx4gWSk5Oz1BRluH37NhYsWIDLly9LzVwZzVsLFy7EkiVLpPdD5tiUSiXKlSuHiIgIletFR0dLNUkFAb+ZtczDwxGNG7sBAMqXt8OxYwMxaVITJkFEVCBMmTIFs2fPxqNHjwCkDwW3t7dXO+Jr+/btuHnzJnr16gUA6NatG8zMzDBz5ky113758qXa8qpVq+LBgwdSE9u7ihUrhsjISJVk6H3NPxlcXV3RpEkTBAUFSf1uMr7QnZycULJkSdy5cwcVKlRQ+Slbtmy216xRowauXr2qUhYUFARXV1dcuHAB58+fl37mzp2LVatWISUlBUB6U2JoaNYk+fTp0yq1Rr1798b+/ftVRl1lSElJyXaunYymsZx+fvjhh2yfW4MGDXD58mU8fvxYKtu3bx+USiVq1aql9pyM2hsjI9XvMWNjYynZrFWrFpRKJa5fvy7tT05Oxt27d+Hm5qZy3uXLl9X2jZKNVrteFwL5MWrs8eNXYsyY3eLVq0SdXJ+I8pc+jRoTQohatWqJkSNHStubNm0SxsbGYsiQIeLChQsiPDxcLFu2TNjZ2Ylu3bqJtLQ06diFCxcKhUIhBg4cKP79919x9+5dcfToUTF06FDh5+eXbSzNmjUTVapUEfv27RN37twRu3btErt37xZCCHH16lWhUCjEzz//LG7duiUWLFgg7Ozs1I4aU+ePP/4QLi4uwtHRUaxZs0ZlX0BAgLCwsBBz584V169fFxcvXhQrVqwQc+bMyTbWixcvChMTExEdHS2VVatWTXz33XdZjo2NjRVKpVJs27ZNCCFEeHi4sLCwECNGjBDnz58X169fFwsWLBBKpVL8+eef0nkJCQmicePGws7OTixYsECcP39e3L59W2zcuFHUrFlTnDt3Ltv4PkRKSoqoUqWKaNmypTh79qzYv3+/cHV1FaNGjZKOefDggfjoo4/EyZMnhRDpo9gqVKggGjduLE6ePClu3bolZs+eLRQKhfj777+l88aMGSNKliwp9u7dK65duyYGDRokihcvrvI6hoeHC4VCIe7evas2PjlGjTER+gCJiSli3Lh9IiTktpaiI6KCSN8SoaCgIGFmZiYiIiKkssOHD4t27doJW1tbYWZmJipVqiRmz54tUlJSspwfEhIi2rZtK+zs7IS5ubnw8PAQ33zzjXj06FG2sURFRYkBAwYIBwcHYW5uLqpUqSJ27twp7V+8eLEoVaqUsLKyEn379hU//fRTrhOhFy9eCKVSKSwtLcWrV6/UPt/q1asLMzMzYWdnJ5o0aSK2bt2abaxCCFG/fn2xZMkSIYQQoaGhAoA4deqU2mO9vb2Ft7e3tB0aGiratm0rihcvLmxsbETt2rXF+vXrs5yXkJAg/P39xccffyzMzc2Fvb29aNSokVi5cqVITk7OMb4Pce/ePdGhQwdhYWEh7O3txahRo0RCQoK0Pzw8XAAQBw8elMpu3LghunTpIooXLy4sLS1F1apVswynT0pKEmPHjhXFixcXRYoUEa1atRKXL19WOWbGjBmibdu22cYmRyKkECKbHnJ6KjY2Fra2toj5EbBxLAkMe5Cn61y79hy9e2/BuXORcHEpgosXh3NpDCI9lZCQgPDwcJQtW1ZtJ1rSP7t27cI333yDy5cvZ2kSorxJTExExYoVsX79ejRq1EjtMTl91qTv75iYHEfGaYp3V0NCCCxZEoqaNZfi3Ln0oYbPnsXh+PH7MkdGRETa4uXlhWHDhunVsiFyu3fvHiZOnJhtEiQXwx41ZlZEo8OfPo3D4MHbsWPH2w5/np6OWLeuK6pXl2koLRER6cSYMWPkDkGvuLu7f/AUCrpg2IlQo+m5PnTPnlvo338bnjx525N/xIjamDWrDSwt1c8ASkRERAWb4SZCVs6Ae7f3HhYfn4zx4/dj3rxTUlmxYpZYseIzfPppwctsiYiIKPcMNxHKpUePXmH58rfzPHh5VcSKFR3h5MTV4okMjYGNLSHKd3J8xthZ+j3Kl7fHvHntYW5uggUL2mPnzl5MgogMTMYsxElJSTJHQqTfMj5jmi7I+yFYI/SOR49eoWhRc5V+PwMGVEfLlmXh5lZUvsCISDYZi0w+e/YMpqamHE5NpANpaWl49uwZLC0tpfXc8gMToUyCg8MwZMgOfP55JSxe/KlUrlAomAQRGTCFQgFnZ2eEh4fj3r17codDpLeMjIxQunTpPC1Im1dMhAC8fp0EX989WLYsvS/QkiVn0KGDOztDE5HEzMwMFStWZPMYkQ6ZmZnle42r7InQokWLMGvWLDx+/BiVK1fG3Llz0bhx42yPP3ToEPz8/HDlyhW4uLhg3LhxGD58eJ4f//Tph/Dx2YqbN6Olss6dPdCggWuer0lE+snIyIgzSxPpGVkbujdu3Iivv/4aEydOxLlz59C4cWO0b98eERERao8PDw+Hl5cXGjdujHPnzuH777/H6NGjsWXLFo0fOzVNAX//I2jYcIWUBFlammLZMm9s2dKdy2UQEREZAFnXGqtXrx5q1qyJxYsXS2Wenp7o1KkT/P39sxz/3XffYfv27QgLC5PKhg8fjgsXLuDEiRO5esyMtUoalhuA43fcpPI6dVwQFNQFFSs6fMAzIiIiIl3Qu7XGkpKScObMGbRp00alvE2bNjh+/Ljac06cOJHl+LZt2yI0NBTJyckaPf7xO04AACMjBSZObIxjxwYyCSIiIjIwsvURev78OVJTU+Hk5KRS7uTkhMjISLXnREZGqj0+JSUFz58/h7Ozc5ZzEhMTkZiYKG3HxMRk7IGrqy0CAj5Fw4alER8fh/j4D3tOREREpBuxsbEAtD/pouydpd8dIieEyHHYnLrj1ZVn8Pf3x7Rp09Ts+Q0PHgDt20/QLGAiIiKSTVRUFGxtbbV2PdkSIUdHRxgbG2ep/Xn69GmWWp8MJUqUUHu8iYkJHBzUN2tNmDABfn5+0vbLly/h5uaGiIgIrb6QlDexsbEoVaoU7t+/r9U2X9Ic70XBwXtRcPBeFBwxMTEoXbo07O3ttXpd2RIhMzMz1KpVCyEhIejcubNUHhISgs8++0ztOQ0aNMCOHTtUyvbt24fatWvD1FT9CvBKpRJKpTJLua2tLd/UBYiNjQ3vRwHBe1Fw8F4UHLwXBYe25xmSdfi8n58fli1bhhUrViAsLAy+vr6IiIiQ5gWaMGEC+vbtKx0/fPhw3Lt3D35+fggLC8OKFSuwfPlyfPPNN3I9BSIiIirEZO0j1KNHD0RFReGHH37A48ePUaVKFezatQtubunD2h8/fqwyp1DZsmWxa9cu+Pr6YuHChXBxccG8efPQtWtXuZ4CERERFWKyd5YeMWIERowYoXbfypUrs5Q1bdoUZ8+ezfPjKZVKTJkyRW1zGeU/3o+Cg/ei4OC9KDh4LwoOXd0LWSdUJCIiIpKTrH2EiIiIiOTERIiIiIgMFhMhIiIiMlhMhIiIiMhg6WUitGjRIpQtWxbm5uaoVasWjhw5kuPxhw4dQq1atWBubo5y5cphyZIl+RSp/tPkXmzduhWtW7dGsWLFYGNjgwYNGmDv3r35GK3+0/SzkeHYsWMwMTFB9erVdRugAdH0XiQmJmLixIlwc3ODUqlE+fLlsWLFinyKVr9pei+CgoJQrVo1WFpawtnZGQMGDEBUVFQ+Rau/Dh8+DG9vb7i4uEChUGDbtm3vPUcr399Cz2zYsEGYmpqKgIAAcfXqVTFmzBhhZWUl7t27p/b4O3fuCEtLSzFmzBhx9epVERAQIExNTcXmzZvzOXL9o+m9GDNmjPjll1/EqVOnxI0bN8SECROEqampOHv2bD5Hrp80vR8ZXr58KcqVKyfatGkjqlWrlj/B6rm83IuOHTuKevXqiZCQEBEeHi5Onjwpjh07lo9R6ydN78WRI0eEkZGR+P3338WdO3fEkSNHROXKlUWnTp3yOXL9s2vXLjFx4kSxZcsWAUAEBwfneLy2vr/1LhGqW7euGD58uEqZh4eHGD9+vNrjx40bJzw8PFTKhg0bJurXr6+zGA2FpvdCnUqVKolp06ZpOzSDlNf70aNHDzFp0iQxZcoUJkJaoum92L17t7C1tRVRUVH5EZ5B0fRezJo1S5QrV06lbN68ecLV1VVnMRqi3CRC2vr+1qumsaSkJJw5cwZt2rRRKW/Tpg2OHz+u9pwTJ05kOb5t27YIDQ1FcnKyzmLVd3m5F+9KS0vDq1evtL7AniHK6/0IDAzE7du3MWXKFF2HaDDyci+2b9+O2rVrY+bMmShZsiTc3d3xzTffID4+Pj9C1lt5uRcNGzbEgwcPsGvXLggh8OTJE2zevBkdOnTIj5ApE219f8s+s7Q2PX/+HKmpqVlWr3dycsqyan2GyMhItcenpKTg+fPncHZ21lm8+iwv9+Jdc+bMQVxcHLp3766LEA1KXu7HzZs3MX78eBw5cgQmJnr1q0JWebkXd+7cwdGjR2Fubo7g4GA8f/4cI0aMQHR0NPsJfYC83IuGDRsiKCgIPXr0QEJCAlJSUtCxY0fMnz8/P0KmTLT1/a1XNUIZFAqFyrYQIkvZ+45XV06a0/ReZFi/fj2mTp2KjRs3onjx4roKz+Dk9n6kpqaid+/emDZtGtzd3fMrPIOiyWcjLS0NCoUCQUFBqFu3Lry8vPDrr79i5cqVrBXSAk3uxdWrVzF69GhMnjwZZ86cwZ49exAeHi4tFk75Sxvf33r1Z56joyOMjY2zZPJPnz7NkjVmKFGihNrjTUxM4ODgoLNY9V1e7kWGjRs3YtCgQdi0aRNatWqlyzANhqb349WrVwgNDcW5c+cwatQoAOlfxkIImJiYYN++fWjRokW+xK5v8vLZcHZ2RsmSJWFrayuVeXp6QgiBBw8eoGLFijqNWV/l5V74+/ujUaNG+PbbbwEAVatWhZWVFRo3bowff/yRrQj5SFvf33pVI2RmZoZatWohJCREpTwkJAQNGzZUe06DBg2yHL9v3z7Url0bpqamOotV3+XlXgDpNUH9+/fHunXr2OauRZreDxsbG1y6dAnnz5+XfoYPH46PPvoI58+fR7169fIrdL2Tl89Go0aN8OjRI7x+/Voqu3HjBoyMjODq6qrTePVZXu7FmzdvYGSk+tVpbGwM4G1tBOUPrX1/a9S1uhDIGAq5fPlycfXqVfH1118LKysrcffuXSGEEOPHjxd9+vSRjs8Yfufr6yuuXr0qli9fzuHzWqLpvVi3bp0wMTERCxcuFI8fP5Z+Xr58KddT0Cua3o93cdSY9mh6L169eiVcXV1Ft27dxJUrV8ShQ4dExYoVxeDBg+V6CnpD03sRGBgoTExMxKJFi8Tt27fF0aNHRe3atUXdunXlegp649WrV+LcuXPi3LlzAoD49ddfxblz56SpDHT1/a13iZAQQixcuFC4ubkJMzMzUbNmTXHo0CFpX79+/UTTpk1Vjv/3339FjRo1hJmZmShTpoxYvHhxPkesvzS5F02bNhUAsvz069cv/wPXU5p+NjJjIqRdmt6LsLAw0apVK2FhYSFcXV2Fn5+fePPmTT5HrZ80vRfz5s0TlSpVEhYWFsLZ2Vn4+PiIBw8e5HPU+ufgwYM5fgfo6vtbIQTr8oiIiMgw6VUfISIiIiJNMBEiIiIig8VEiIiIiAwWEyEiIiIyWEyEiIiIyGAxESIiIiKDxUSIiIiIDBYTISJSsXLlShQtWlTuMPKsTJkymDt3bo7HTJ06FdWrV8+XeIioYGMiRKSH+vfvD4VCkeXn1q1bcoeGlStXqsTk7OyM7t27Izw8XCvXP336NIYOHSptKxQKbNu2TeWYb775BgcOHNDK42Xn3efp5OQEb29vXLlyRePrFObElKigYyJEpKfatWuHx48fq/yULVtW7rAApC/q+vjxYzx69Ajr1q3D+fPn0bFjR6Smpn7wtYsVKwZLS8scj7G2ttZodeq8yvw8//77b8TFxaFDhw5ISkrS+WMTUe4wESLSU0qlEiVKlFD5MTY2xq+//oqPP/4YVlZWKFWqFEaMGKGyqvm7Lly4gObNm6NIkSKwsbFBrVq1EBoaKu0/fvw4mjRpAgsLC5QqVQqjR49GXFxcjrEpFAqUKFECzs7OaN68OaZMmYLLly9LNVaLFy9G+fLlYWZmho8++ghr1qxROX/q1KkoXbo0lEolXFxcMHr0aGlf5qaxMmXKAAA6d+4MhUIhbWduGtu7dy/Mzc3x8uVLlccYPXo0mjZtqrXnWbt2bfj6+uLevXu4fv26dExO9+Pff//FgAEDEBMTI9UsTZ06FQCQlJSEcePGoWTJkrCyskK9evXw77//5hgPEWXFRIjIwBgZGWHevHm4fPkyVq1ahX/++Qfjxo3L9ngfHx+4urri9OnTOHPmDMaPHw9TU1MAwKVLl9C2bVt06dIFFy9exMaNG3H06FGMGjVKo5gsLCwAAMnJyQgODsaYMWMwduxYXL58GcOGDcOAAQNw8OBBAMDmzZvx22+/YenSpbh58ya2bduGjz/+WO11T58+DQAIDAzE48ePpe3MWrVqhaJFi2LLli1SWWpqKv7880/4+Pho7Xm+fPkS69atAwDp9QNyvh8NGzbE3LlzpZqlx48f45tvvgEADBgwAMeOHcOGDRtw8eJFfP7552jXrh1u3ryZ65iICNDL1eeJDF2/fv2EsbGxsLKykn66deum9tg///xTODg4SNuBgYHC1tZW2i5SpIhYuXKl2nP79Okjhg4dqlJ25MgRYWRkJOLj49We8+7179+/L+rXry9cXV1FYmKiaNiwoRgyZIjKOZ9//rnw8vISQggxZ84c4e7uLpKSktRe383NTfz222/SNgARHByscsyUKVNEtWrVpO3Ro0eLFi1aSNt79+4VZmZmIjo6+oOeJwBhZWUlLC0tpZW0O3bsqPb4DO+7H0IIcevWLaFQKMTDhw9Vylu2bCkmTJiQ4/WJSJWJvGkYEelK8+bNsXjxYmnbysoKAHDw4EHMmDEDV69eRWxsLFJSUpCQkIC4uDjpmMz8/PwwePBgrFmzBq1atcLnn3+O8uXLAwDOnDmDW7duISgoSDpeCIG0tDSEh4fD09NTbWwxMTGwtraGEAJv3rxBzZo1sXXrVpiZmSEsLEylszMANGrUCL///jsA4PPPP8fcuXNRrlw5tGvXDl5eXvD29oaJSd5/nfn4+KBBgwZ49OgRXFxcEBQUBC8vL9jZ2X3Q8yxSpAjOnj2LlJQUHDp0CLNmzcKSJUtUjtH0fgDA2bNnIYSAu7u7SnliYmK+9H0i0idMhIj0lJWVFSpUqKBSdu/ePXh5eWH48OGYPn067O3tcfToUQwaNAjJyclqrzN16lT07t0bf//9N3bv3o0pU6Zgw4YN6Ny5M9LS0jBs2DCVPjoZSpcunW1sGQmCkZERnJycsnzhKxQKlW0hhFRWqlQpXL9+HSEhIdi/fz9GjBiBWbNm4dChQypNTpqoW7cuypcvjw0bNuDLL79EcHAwAgMDpf15fZ5GRkbSPfDw8EBkZCR69OiBw4cPA8jb/ciIx9jYGGfOnIGxsbHKPmtra42eO5GhYyJEZEBCQ0ORkpKCOXPmwMgovYvgn3/++d7z3N3d4e7uDl9fX/Tq1QuBgYHo3LkzatasiStXrmRJuN4nc4LwLk9PTxw9ehR9+/aVyo4fP65S62JhYYGOHTuiY8eOGDlyJDw8PHDp0iXUrFkzy/VMTU1zNRqtd+/eCAoKgqurK4yMjNChQwdpX16f57t8fX3x66+/Ijg4GJ07d87V/TAzM8sSf40aNZCamoqnT5+icePGHxQTkaFjZ2kiA1K+fHmkpKRg/vz5uHPnDtasWZOlqSaz+Ph4jBo1Cv/++y/u3buHY8eO4fTp01JS8t133+HEiRMYOXIkzp8/j5s3b2L79u346quv8hzjt99+i5UrV2LJkiW4efMmfv31V2zdulXqJLxy5UosX74cly9flp6DhYUF3Nzc1F6vTJkyOHDgACIjI/HixYtsH9fHxwdnz57FTz/9hG7dusHc3Fzap63naWNjg8GDB2PKlCkQQuTqfpQpUwavX7/GgQMH8Pz5c7x58wbu7u7w8fFB3759sXXrVoSHh+P06dP45ZdfsGvXLo1iIjJ4cnZQIiLd6Nevn/jss8/U7vv111+Fs7OzsLCwEG3bthWrV68WAMSLFy+EEKqdcxMTE0XPnj1FqVKlhJmZmXBxcRGjRo1S6SB86tQp0bp1a2FtbS2srKxE1apVxU8//ZRtbOo6/75r0aJFoly5csLU1FS4u7uL1atXS/uCg4NFvXr1hI2NjbCyshL169cX+/fvl/a/21l6+/btokKFCsLExES4ubkJIbJ2ls5Qp04dAUD8888/WfZp63neu3dPmJiYiI0bNwoh3n8/hBBi+PDhwsHBQQAQU6ZMEUIIkZSUJCZPnizKlCkjTE1NRYkSJUTnzp3FxYsXs42JiLJSCCGEvKkYERERkTzYNEZEREQGi4kQERERGSwmQkRERGSwmAgRERGRwWIiRERERAaLiRAREREZLCZCREREZLCYCBEREZHBYiJEREREBouJEBERERksJkJERERksJgIERERkcH6Py38IcRxEbIHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# Plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(Y_test_final, mlp_model_final.predict(X_test_final))\n",
    "roc_auc_value = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc_value:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078c1dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>PID</th>\n",
       "      <th>sequence_window</th>\n",
       "      <th>Position</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>Feature_1_A1</th>\n",
       "      <th>Feature_2_A1</th>\n",
       "      <th>Feature_3_A1</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_2551_A3</th>\n",
       "      <th>Feature_2552_A3</th>\n",
       "      <th>Feature_2553_A3</th>\n",
       "      <th>Feature_2554_A3</th>\n",
       "      <th>Feature_2555_A3</th>\n",
       "      <th>Feature_2556_A3</th>\n",
       "      <th>Feature_2557_A3</th>\n",
       "      <th>Feature_2558_A3</th>\n",
       "      <th>Feature_2559_A3</th>\n",
       "      <th>Feature_2560_A3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A6NK06</td>\n",
       "      <td>DRSDTFYGHWRKPLSQEDLEEKFRANASKMLSWDTVESLIKIVKNL...</td>\n",
       "      <td>425</td>\n",
       "      <td>N</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>0.102742</td>\n",
       "      <td>-0.119910</td>\n",
       "      <td>-0.027533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078203</td>\n",
       "      <td>-0.084310</td>\n",
       "      <td>0.065748</td>\n",
       "      <td>-0.228966</td>\n",
       "      <td>0.036301</td>\n",
       "      <td>-0.018697</td>\n",
       "      <td>0.085146</td>\n",
       "      <td>0.020588</td>\n",
       "      <td>0.341293</td>\n",
       "      <td>-0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A6NNS2</td>\n",
       "      <td>SDISCVPDVAKEVLDCYGCVDILINNASVKVKGPAHKISLELDKKI...</td>\n",
       "      <td>127</td>\n",
       "      <td>N</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>-0.022113</td>\n",
       "      <td>0.083495</td>\n",
       "      <td>-0.126984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184083</td>\n",
       "      <td>0.102966</td>\n",
       "      <td>-0.167790</td>\n",
       "      <td>-0.333483</td>\n",
       "      <td>0.029495</td>\n",
       "      <td>-0.031681</td>\n",
       "      <td>0.034087</td>\n",
       "      <td>0.181541</td>\n",
       "      <td>-0.157947</td>\n",
       "      <td>0.048032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>O00629</td>\n",
       "      <td>EDICEDSDIDGDYRVQNTSLEAIVQNASSDNQGIQLSAVQAARKLL...</td>\n",
       "      <td>79</td>\n",
       "      <td>N</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>0.021770</td>\n",
       "      <td>-0.157243</td>\n",
       "      <td>-0.075847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188142</td>\n",
       "      <td>0.109580</td>\n",
       "      <td>0.077411</td>\n",
       "      <td>-0.132088</td>\n",
       "      <td>-0.035766</td>\n",
       "      <td>-0.131703</td>\n",
       "      <td>-0.248742</td>\n",
       "      <td>0.255177</td>\n",
       "      <td>0.069867</td>\n",
       "      <td>-0.045436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>O14556</td>\n",
       "      <td>SPDAPMFVMGVNENDYNPGSMNIVSNASCTTNCLAPLAKVIHERFG...</td>\n",
       "      <td>221</td>\n",
       "      <td>N</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>-0.044578</td>\n",
       "      <td>-0.150903</td>\n",
       "      <td>-0.041899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106943</td>\n",
       "      <td>-0.096906</td>\n",
       "      <td>0.080183</td>\n",
       "      <td>0.112341</td>\n",
       "      <td>-0.094210</td>\n",
       "      <td>-0.085395</td>\n",
       "      <td>0.108746</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>0.136389</td>\n",
       "      <td>0.094940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>O14657</td>\n",
       "      <td>AITGYLSYNDIYCRFAECCREERPLNASALKLDLEEKLFGQHLATE...</td>\n",
       "      <td>64</td>\n",
       "      <td>N</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>-0.148869</td>\n",
       "      <td>0.130875</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150824</td>\n",
       "      <td>-0.104798</td>\n",
       "      <td>0.210740</td>\n",
       "      <td>-0.053255</td>\n",
       "      <td>-0.047107</td>\n",
       "      <td>-0.073082</td>\n",
       "      <td>0.138224</td>\n",
       "      <td>0.074727</td>\n",
       "      <td>-0.209900</td>\n",
       "      <td>-0.045697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>0</td>\n",
       "      <td>Q17QL5</td>\n",
       "      <td>NNIREIEIDYTGTDPSSPCNKCLSPNVTPCVCTINFTLEQSFEGNV...</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.023070</td>\n",
       "      <td>0.109733</td>\n",
       "      <td>0.081716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137606</td>\n",
       "      <td>0.123354</td>\n",
       "      <td>0.145751</td>\n",
       "      <td>-0.476924</td>\n",
       "      <td>0.041688</td>\n",
       "      <td>-0.191985</td>\n",
       "      <td>0.022479</td>\n",
       "      <td>0.132160</td>\n",
       "      <td>-0.214497</td>\n",
       "      <td>-0.034384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>0</td>\n",
       "      <td>P80607</td>\n",
       "      <td>SNPFVNLKKEYKGIFWQEDIIPFFQNVTIPKDCDTVQKCYIYLSGQ...</td>\n",
       "      <td>302</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>T</td>\n",
       "      <td>0.086859</td>\n",
       "      <td>-0.173323</td>\n",
       "      <td>0.053590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184671</td>\n",
       "      <td>-0.313492</td>\n",
       "      <td>0.010292</td>\n",
       "      <td>0.177867</td>\n",
       "      <td>0.056666</td>\n",
       "      <td>0.085160</td>\n",
       "      <td>-0.200305</td>\n",
       "      <td>-0.022898</td>\n",
       "      <td>-0.168454</td>\n",
       "      <td>0.122788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>0</td>\n",
       "      <td>Q8VEK0</td>\n",
       "      <td>NNIREIEIDYTGTEPSSPCNKCLSPNVTSCACTINFTLKQSFEGNV...</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>T</td>\n",
       "      <td>0.012969</td>\n",
       "      <td>0.098343</td>\n",
       "      <td>0.121864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155972</td>\n",
       "      <td>0.170843</td>\n",
       "      <td>0.125797</td>\n",
       "      <td>-0.431157</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>-0.173429</td>\n",
       "      <td>-0.000453</td>\n",
       "      <td>0.079545</td>\n",
       "      <td>-0.151662</td>\n",
       "      <td>-0.021575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>0</td>\n",
       "      <td>Q9D2A5</td>\n",
       "      <td>QGQSEARPEDYQLHGVISRNILTHENVTENLESPVLKSKLEELPEA...</td>\n",
       "      <td>318</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>T</td>\n",
       "      <td>0.134084</td>\n",
       "      <td>-0.122141</td>\n",
       "      <td>0.167665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027352</td>\n",
       "      <td>0.058908</td>\n",
       "      <td>-0.074485</td>\n",
       "      <td>-0.028644</td>\n",
       "      <td>0.204522</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.049196</td>\n",
       "      <td>0.085412</td>\n",
       "      <td>-0.170312</td>\n",
       "      <td>0.015078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>0</td>\n",
       "      <td>Q9DA32</td>\n",
       "      <td>DKARSYWNWIRLWNYAQPPDVILEPNVTPGNCWAFASDRGQVTIRL...</td>\n",
       "      <td>243</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.070960</td>\n",
       "      <td>0.315455</td>\n",
       "      <td>0.111632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327892</td>\n",
       "      <td>-0.044184</td>\n",
       "      <td>-0.032709</td>\n",
       "      <td>0.235644</td>\n",
       "      <td>-0.017254</td>\n",
       "      <td>-0.062665</td>\n",
       "      <td>-0.007385</td>\n",
       "      <td>-0.095335</td>\n",
       "      <td>-0.316385</td>\n",
       "      <td>0.228727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows × 7687 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     PID                                    sequence_window  \\\n",
       "0         1  A6NK06  DRSDTFYGHWRKPLSQEDLEEKFRANASKMLSWDTVESLIKIVKNL...   \n",
       "1         1  A6NNS2  SDISCVPDVAKEVLDCYGCVDILINNASVKVKGPAHKISLELDKKI...   \n",
       "2         1  O00629  EDICEDSDIDGDYRVQNTSLEAIVQNASSDNQGIQLSAVQAARKLL...   \n",
       "3         1  O14556  SPDAPMFVMGVNENDYNPGSMNIVSNASCTTNCLAPLAKVIHERFG...   \n",
       "4         1  O14657  AITGYLSYNDIYCRFAECCREERPLNASALKLDLEEKLFGQHLATE...   \n",
       "...     ...     ...                                                ...   \n",
       "4855      0  Q17QL5  NNIREIEIDYTGTDPSSPCNKCLSPNVTPCVCTINFTLEQSFEGNV...   \n",
       "4856      0  P80607  SNPFVNLKKEYKGIFWQEDIIPFFQNVTIPKDCDTVQKCYIYLSGQ...   \n",
       "4857      0  Q8VEK0  NNIREIEIDYTGTEPSSPCNKCLSPNVTSCACTINFTLKQSFEGNV...   \n",
       "4858      0  Q9D2A5  QGQSEARPEDYQLHGVISRNILTHENVTENLESPVLKSKLEELPEA...   \n",
       "4859      0  Q9DA32  DKARSYWNWIRLWNYAQPPDVILEPNVTPGNCWAFASDRGQVTIRL...   \n",
       "\n",
       "      Position A1 A2 A3  Feature_1_A1  Feature_2_A1  Feature_3_A1  ...  \\\n",
       "0          425  N  A  S      0.102742     -0.119910     -0.027533  ...   \n",
       "1          127  N  A  S     -0.022113      0.083495     -0.126984  ...   \n",
       "2           79  N  A  S      0.021770     -0.157243     -0.075847  ...   \n",
       "3          221  N  A  S     -0.044578     -0.150903     -0.041899  ...   \n",
       "4           64  N  A  S     -0.148869      0.130875      0.004870  ...   \n",
       "...        ... .. .. ..           ...           ...           ...  ...   \n",
       "4855        98  N  V  T     -0.023070      0.109733      0.081716  ...   \n",
       "4856       302  N  V  T      0.086859     -0.173323      0.053590  ...   \n",
       "4857        98  N  V  T      0.012969      0.098343      0.121864  ...   \n",
       "4858       318  N  V  T      0.134084     -0.122141      0.167665  ...   \n",
       "4859       243  N  V  T     -0.070960      0.315455      0.111632  ...   \n",
       "\n",
       "      Feature_2551_A3  Feature_2552_A3  Feature_2553_A3  Feature_2554_A3  \\\n",
       "0           -0.078203        -0.084310         0.065748        -0.228966   \n",
       "1           -0.184083         0.102966        -0.167790        -0.333483   \n",
       "2            0.188142         0.109580         0.077411        -0.132088   \n",
       "3            0.106943        -0.096906         0.080183         0.112341   \n",
       "4            0.150824        -0.104798         0.210740        -0.053255   \n",
       "...               ...              ...              ...              ...   \n",
       "4855        -0.137606         0.123354         0.145751        -0.476924   \n",
       "4856         0.184671        -0.313492         0.010292         0.177867   \n",
       "4857        -0.155972         0.170843         0.125797        -0.431157   \n",
       "4858         0.027352         0.058908        -0.074485        -0.028644   \n",
       "4859         0.327892        -0.044184        -0.032709         0.235644   \n",
       "\n",
       "      Feature_2555_A3  Feature_2556_A3  Feature_2557_A3  Feature_2558_A3  \\\n",
       "0            0.036301        -0.018697         0.085146         0.020588   \n",
       "1            0.029495        -0.031681         0.034087         0.181541   \n",
       "2           -0.035766        -0.131703        -0.248742         0.255177   \n",
       "3           -0.094210        -0.085395         0.108746         0.011008   \n",
       "4           -0.047107        -0.073082         0.138224         0.074727   \n",
       "...               ...              ...              ...              ...   \n",
       "4855         0.041688        -0.191985         0.022479         0.132160   \n",
       "4856         0.056666         0.085160        -0.200305        -0.022898   \n",
       "4857         0.004961        -0.173429        -0.000453         0.079545   \n",
       "4858         0.204522         0.004282         0.049196         0.085412   \n",
       "4859        -0.017254        -0.062665        -0.007385        -0.095335   \n",
       "\n",
       "      Feature_2559_A3  Feature_2560_A3  \n",
       "0            0.341293        -0.048000  \n",
       "1           -0.157947         0.048032  \n",
       "2            0.069867        -0.045436  \n",
       "3            0.136389         0.094940  \n",
       "4           -0.209900        -0.045697  \n",
       "...               ...              ...  \n",
       "4855        -0.214497        -0.034384  \n",
       "4856        -0.168454         0.122788  \n",
       "4857        -0.151662        -0.021575  \n",
       "4858        -0.170312         0.015078  \n",
       "4859        -0.316385         0.228727  \n",
       "\n",
       "[4860 rows x 7687 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data= pd.read_csv(\"three_rows.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d810d09",
   "metadata": {},
   "source": [
    "# saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc4297a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded features: 22\n",
      "Number of numerical features: 7680\n",
      "Total input features: 7702\n",
      "Epoch 1/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 87ms/step - accuracy: 0.5941 - loss: 2.2604 - val_accuracy: 0.7562 - val_loss: 2.0884\n",
      "Epoch 2/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.8389 - loss: 1.9341 - val_accuracy: 0.7767 - val_loss: 1.9977\n",
      "Epoch 3/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.8947 - loss: 1.7329 - val_accuracy: 0.7798 - val_loss: 1.9061\n",
      "Epoch 4/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.9501 - loss: 1.5517 - val_accuracy: 0.7798 - val_loss: 1.8664\n",
      "Epoch 5/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9673 - loss: 1.4212 - val_accuracy: 0.7870 - val_loss: 1.8407\n",
      "Epoch 6/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9705 - loss: 1.2999 - val_accuracy: 0.7891 - val_loss: 1.8040\n",
      "Epoch 7/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9764 - loss: 1.1936 - val_accuracy: 0.7850 - val_loss: 1.7249\n",
      "Epoch 8/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9759 - loss: 1.1060 - val_accuracy: 0.7809 - val_loss: 1.6746\n",
      "Epoch 9/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9817 - loss: 1.0144 - val_accuracy: 0.7644 - val_loss: 1.6892\n",
      "Epoch 10/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9727 - loss: 0.9555 - val_accuracy: 0.7695 - val_loss: 1.6943\n",
      "Epoch 11/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9521 - loss: 0.9574 - val_accuracy: 0.7695 - val_loss: 1.6401\n",
      "Epoch 12/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9604 - loss: 0.9118 - val_accuracy: 0.7593 - val_loss: 1.6828\n",
      "Epoch 13/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9720 - loss: 0.8509 - val_accuracy: 0.7654 - val_loss: 1.6530\n",
      "Epoch 14/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9762 - loss: 0.7964 - val_accuracy: 0.7716 - val_loss: 1.6219\n",
      "Epoch 15/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9812 - loss: 0.7360 - val_accuracy: 0.7840 - val_loss: 1.5417\n",
      "Epoch 16/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9814 - loss: 0.6789 - val_accuracy: 0.7778 - val_loss: 1.4869\n",
      "Epoch 17/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9885 - loss: 0.6207 - val_accuracy: 0.7778 - val_loss: 1.5013\n",
      "Epoch 18/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9863 - loss: 0.5890 - val_accuracy: 0.7654 - val_loss: 1.4890\n",
      "Epoch 19/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9793 - loss: 0.5804 - val_accuracy: 0.7685 - val_loss: 1.5062\n",
      "Epoch 20/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9639 - loss: 0.6244 - val_accuracy: 0.7623 - val_loss: 1.5183\n",
      "Epoch 21/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9681 - loss: 0.6035 - val_accuracy: 0.7644 - val_loss: 1.5551\n",
      "Epoch 22/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9717 - loss: 0.5770 - val_accuracy: 0.7747 - val_loss: 1.6065\n",
      "Epoch 23/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9737 - loss: 0.5540 - val_accuracy: 0.7747 - val_loss: 1.5682\n",
      "Epoch 24/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9761 - loss: 0.5231 - val_accuracy: 0.7603 - val_loss: 1.5522\n",
      "Epoch 25/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9793 - loss: 0.4825 - val_accuracy: 0.7685 - val_loss: 1.4647\n",
      "Epoch 26/400\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9815 - loss: 0.4546 - val_accuracy: 0.7788 - val_loss: 1.4562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and preprocessors saved.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Final Training Accuracy: 0.9781378507614136\n",
      "Final Testing Accuracy: 0.7788065671920776\n",
      "\n",
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79       486\n",
      "           1       0.78      0.80      0.79       486\n",
      "\n",
      "    accuracy                           0.79       972\n",
      "   macro avg       0.79      0.79      0.79       972\n",
      "weighted avg       0.79      0.79      0.79       972\n",
      "\n",
      "Accuracy: 0.7890946502057613\n",
      "Precision: 0.7849898580121704\n",
      "Recall: 0.7962962962962963\n",
      "F1-Score: 0.7906026557711952\n",
      "ROC AUC: 0.7890946502057614\n",
      "\n",
      "Confusion Matrix:\n",
      "[[380 106]\n",
      " [ 99 387]]\n",
      "False Positives: 106\n",
      "False Negatives: 99\n",
      "True Positives: 387\n",
      "True Negatives: 380\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import joblib\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"three_rows.csv\")\n",
    "\n",
    "# Extract target variable (Y)\n",
    "Y = df['label']\n",
    "\n",
    "# Identify categorical amino acid columns\n",
    "amino_acid_cols = [\"A1\", \"A2\", \"A3\"]\n",
    "\n",
    "# Apply One-Hot Encoding (OHE) for A1, A2, A3\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "encoded_amino_acids = encoder.fit_transform(df[amino_acid_cols])\n",
    "\n",
    "# Convert to DataFrame with proper column names\n",
    "encoded_cols = encoder.get_feature_names_out(amino_acid_cols)\n",
    "encoded_amino_acids_df = pd.DataFrame(encoded_amino_acids, columns=encoded_cols, index=df.index)\n",
    "print(f\"One-hot encoded features: {len(encoded_cols)}\")\n",
    "\n",
    "# Drop original A1, A2, A3 columns from df\n",
    "df.drop(columns=amino_acid_cols, inplace=True)\n",
    "\n",
    "# Merge the encoded features back into the dataset\n",
    "df = pd.concat([df, encoded_amino_acids_df], axis=1)\n",
    "\n",
    "# Select numerical features (only columns starting with 'Feature_')\n",
    "numerical_cols = [col for col in df.columns if col.startswith(\"Feature_\")]\n",
    "X_numerical_features = df[numerical_cols].values\n",
    "print(f\"Number of numerical features: {X_numerical_features.shape[1]}\")\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_numerical_features_scaled = scaler.fit_transform(X_numerical_features)\n",
    "\n",
    "# Combine encoded categorical and scaled numerical features\n",
    "X_independent = np.hstack((encoded_amino_acids, X_numerical_features_scaled))\n",
    "print(f\"Total input features: {X_independent.shape[1]}\")\n",
    "\n",
    "# Split dataset into training (80%) and testing (20%)\n",
    "X_train_final, X_test_final, Y_train_final, Y_test_final = train_test_split(\n",
    "    X_independent, Y, test_size=0.2, random_state=SEED, stratify=Y\n",
    ")\n",
    "\n",
    "# Define improved MLP model architecture\n",
    "mlp_model_final = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_final.shape[1],)),\n",
    "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(256, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(128, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile model with custom learning rate\n",
    "mlp_model_final.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005), \n",
    "                        loss='binary_crossentropy', \n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "# Set up EarlyStopping callback with increased patience\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Train model with smaller batch size\n",
    "history_final = mlp_model_final.fit(\n",
    "    X_train_final, Y_train_final, epochs=400, batch_size=64,\n",
    "    validation_data=(X_test_final, Y_test_final), callbacks=[early_stopping], verbose=1\n",
    ")\n",
    "\n",
    "# Save the model and preprocessors\n",
    "mlp_model_final.save(\"nglycosylation_pred_model_80%.h5\")\n",
    "joblib.dump(encoder, \"one_hot_encoder.pkl\")\n",
    "joblib.dump(scaler, \"standard_scaler.pkl\")\n",
    "print(\"✅ Model and preprocessors saved.\")\n",
    "\n",
    "# Retrieve final training and testing accuracy\n",
    "final_train_accuracy = history_final.history['accuracy'][-1]  \n",
    "final_test_accuracy = history_final.history['val_accuracy'][-1]\n",
    "\n",
    "# Get predictions on test set\n",
    "Y_pred_final = mlp_model_final.predict(X_test_final)\n",
    "Y_pred_final = (Y_pred_final > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(Y_test_final, Y_pred_final)\n",
    "precision = precision_score(Y_test_final, Y_pred_final)\n",
    "recall = recall_score(Y_test_final, Y_pred_final)\n",
    "f1 = f1_score(Y_test_final, Y_pred_final)\n",
    "roc_auc = roc_auc_score(Y_test_final, Y_pred_final)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test_final, Y_pred_final)\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "# Print results\n",
    "print(f\"Final Training Accuracy: {final_train_accuracy}\")\n",
    "print(f\"Final Testing Accuracy: {final_test_accuracy}\")\n",
    "print(\"\\nFinal Classification Report:\")\n",
    "print(classification_report(Y_test_final, Y_pred_final))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"False Positives: {FP}\")\n",
    "print(f\"False Negatives: {FN}\")\n",
    "print(f\"True Positives: {TP}\")\n",
    "print(f\"True Negatives: {TN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f3dd29",
   "metadata": {},
   "source": [
    "# prediction using saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1b7c416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and preprocessors loaded.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "\n",
      "Prediction Results:\n",
      "Sample 1: Glycosylated (Probability: 0.6419)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import joblib\n",
    "\n",
    "# Load the saved model and preprocessors\n",
    "mlp_model = keras.models.load_model(\"nglycosylation_pred_model_80%.h5\")\n",
    "encoder = joblib.load(\"one_hot_encoder.pkl\")\n",
    "scaler = joblib.load(\"standard_scaler.pkl\")\n",
    "print(\"✅ Model and preprocessors loaded.\")\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(r\"C:\\Users\\harsh\\Downloads\\Q16653_flattened_features.csv\")\n",
    "\n",
    "# Preprocess the test data\n",
    "amino_acid_cols = [\"A1\", \"A2\", \"A3\"]\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "encoded_amino_acids = encoder.transform(test_df[amino_acid_cols])\n",
    "encoded_cols = encoder.get_feature_names_out(amino_acid_cols)\n",
    "encoded_amino_acids_df = pd.DataFrame(encoded_amino_acids, columns=encoded_cols, index=test_df.index)\n",
    "\n",
    "# Drop original amino acid columns and any irrelevant columns (e.g., sequence_window, Position)\n",
    "test_df.drop(columns=amino_acid_cols + ['sequence_window', 'Position'], inplace=True, errors='ignore')\n",
    "\n",
    "# Scale numerical features\n",
    "numerical_features = test_df.values\n",
    "numerical_features_scaled = scaler.transform(numerical_features)\n",
    "\n",
    "# Combine encoded categorical and scaled numerical features\n",
    "X_test = np.hstack((encoded_amino_acids, numerical_features_scaled))\n",
    "\n",
    "# Make predictions\n",
    "predictions = mlp_model.predict(X_test)\n",
    "predictions_binary = (predictions > 0.5).astype(int).flatten()\n",
    "probabilities = predictions.flatten()\n",
    "\n",
    "# Display results\n",
    "print(\"\\nPrediction Results:\")\n",
    "for i, (pred, prob) in enumerate(zip(predictions_binary, probabilities)):\n",
    "    label = \"Glycosylated\" if pred == 1 else \"Not Glycosylated\"\n",
    "    print(f\"Sample {i+1}: {label} (Probability: {prob:.4f})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9244dfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and preprocessors loaded.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step\n",
      "\n",
      "🔍 Prediction Results:\n",
      "Position 50: Not Glycosylated (Probability: 0.0433)\n",
      "Position 138: Not Glycosylated (Probability: 0.3218)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import joblib\n",
    "\n",
    "# --------------------- LOAD MODEL AND PREPROCESSORS ---------------------\n",
    "mlp_model = keras.models.load_model(\"nglycosylation_pred_model_80%.h5\")\n",
    "encoder = joblib.load(\"one_hot_encoder.pkl\")\n",
    "scaler = joblib.load(\"standard_scaler.pkl\")\n",
    "print(\"✅ Model and preprocessors loaded.\")\n",
    "\n",
    "# --------------------- LOAD TEST DATA ---------------------\n",
    "test_df = pd.read_csv(r\"C:\\Users\\harsh\\Downloads\\P53178_flattened_features.csv\")\n",
    "\n",
    "# --------------------- SAVE POSITION BEFORE DROPPING ---------------------\n",
    "positions = test_df['Position'].values if 'Position' in test_df.columns else np.arange(len(test_df))\n",
    "\n",
    "# --------------------- ENCODE AMINO ACID COLUMNS ---------------------\n",
    "amino_acid_cols = [\"A1\", \"A2\", \"A3\"]\n",
    "encoded_amino_acids = encoder.transform(test_df[amino_acid_cols])\n",
    "encoded_cols = encoder.get_feature_names_out(amino_acid_cols)\n",
    "encoded_amino_acids_df = pd.DataFrame(encoded_amino_acids, columns=encoded_cols, index=test_df.index)\n",
    "\n",
    "# --------------------- DROP UNUSED COLUMNS ---------------------\n",
    "test_df.drop(columns=amino_acid_cols + ['sequence_window'], inplace=True, errors='ignore')\n",
    "\n",
    "# --------------------- SCALE NUMERICAL FEATURES ---------------------\n",
    "numerical_features = test_df.drop(columns=['Position'], errors='ignore').values  # Ensure Position not included\n",
    "numerical_features_scaled = scaler.transform(numerical_features)\n",
    "\n",
    "# --------------------- COMBINE FEATURES ---------------------\n",
    "X_test = np.hstack((encoded_amino_acids, numerical_features_scaled))\n",
    "\n",
    "# --------------------- MAKE PREDICTIONS ---------------------\n",
    "predictions = mlp_model.predict(X_test)\n",
    "predictions_binary = (predictions > 0.5).astype(int).flatten()\n",
    "probabilities = predictions.flatten()\n",
    "\n",
    "# --------------------- DISPLAY RESULTS ---------------------\n",
    "print(\"\\n🔍 Prediction Results:\")\n",
    "for i, (pos, pred, prob) in enumerate(zip(positions, predictions_binary, probabilities)):\n",
    "    label = \"Glycosylated\" if pred == 1 else \"Not Glycosylated\"\n",
    "    print(f\"Position {pos}: {label} (Probability: {prob:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
